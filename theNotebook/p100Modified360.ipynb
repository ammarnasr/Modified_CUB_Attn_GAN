{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p100Modified360.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKMXRp_ZY4su",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "c73a3d6b-537d-4315-edc4-40394f78f202"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 28 19:25:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb2RUyCra1Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!rm -r sample_data\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of9kI30fbZWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "4f9601cf-22a4-43d2-d4ed-2babd61793fa"
      },
      "source": [
        "#clone repo AttnGAN\n",
        "os.chdir('/content/')\n",
        "!rm -r AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'AttnGAN': No such file or directory\n",
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 37.75 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mXQOOMKfCQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "84938cd7-2d51-466f-9106-f4ebca282502"
      },
      "source": [
        "# Download captionts filenames and classes info\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-28 19:52:27--  https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.216.100, 173.194.216.113, 173.194.216.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.216.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rddo9177608vr08k2aq7feqcubba3ki7/1593373950000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-06-28 19:52:56--  https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rddo9177608vr08k2aq7feqcubba3ki7/1593373950000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download\n",
            "Resolving doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)... 172.217.193.132, 2607:f8b0:400c:c03::84\n",
            "Connecting to doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)|172.217.193.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘birds.zip’\n",
            "\n",
            "birds.zip               [ <=>                ]   6.19M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-06-28 19:52:57 (160 MB/s) - ‘birds.zip’ saved [6488322]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2o_gljRfCG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "a136adf1-d9de-40f8-b97d-0d6123bda9df"
      },
      "source": [
        "# Download Cub Datatset\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!wget http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-28 19:53:02--  http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
            "Resolving www.vision.caltech.edu (www.vision.caltech.edu)... 34.208.54.77\n",
            "Connecting to www.vision.caltech.edu (www.vision.caltech.edu)|34.208.54.77|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1150585339 (1.1G) [application/x-tar]\n",
            "Saving to: ‘CUB_200_2011.tgz’\n",
            "\n",
            "CUB_200_2011.tgz    100%[===================>]   1.07G  14.8MB/s    in 1m 59s  \n",
            "\n",
            "2020-06-28 19:55:01 (9.22 MB/s) - ‘CUB_200_2011.tgz’ saved [1150585339/1150585339]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uapMBGvvfB-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "162ec6aa-9dd4-4ffc-8ff1-a19f11ded2b5"
      },
      "source": [
        "#Dwonload files text encoder and image encoder\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "# #Move Models text and image encoder to their /content/\n",
        "!mv  /content/CUB-Attn-GAN/theModel/text_encoder599.pth  /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "\n",
        "!rm -r CUB-Attn-GAN "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'bird/': No such file or directory\n",
            "Cloning into 'CUB-Attn-GAN'...\n",
            "remote: Enumerating objects: 502, done.\u001b[K\n",
            "remote: Total 502 (delta 0), reused 0 (delta 0), pack-reused 502\u001b[K\n",
            "Receiving objects: 100% (502/502), 262.95 MiB | 44.56 MiB/s, done.\n",
            "Resolving deltas: 100% (279/279), done.\n",
            "Checking out files: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXRAZMSDfQPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download Pillow Font\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKY0AQ4ZfdZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netG_epoch_360.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhFfBIDqfza1",
        "colab_type": "text"
      },
      "source": [
        "# ========================================================"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbCDidIKffyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "b30d0028-cb0b-45dc-b8c4-76d90573bda2"
      },
      "source": [
        "#Move code files to their Locations\n",
        "os.chdir('/content')\n",
        "!rm -r Modified_CUB_Attn_GAN/\n",
        "!git clone https://github.com/ammarnasr/Modified_CUB_Attn_GAN.git\n",
        "\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/config.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/utils.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/datasets.py                  /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/GlobalAttention.py          /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/model.py                   /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/losses.py                 /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/trainer.py               /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/bird_attn2.yml          /content/AttnGAN/code/cfg/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'Modified_CUB_Attn_GAN/': No such file or directory\n",
            "Cloning into 'Modified_CUB_Attn_GAN'...\n",
            "remote: Enumerating objects: 108, done.\u001b[K\n",
            "remote: Counting objects: 100% (108/108), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 108 (delta 42), reused 93 (delta 30), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (108/108), 64.57 KiB | 5.87 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhS0oGMFf3Vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2047af40-d8cb-47fe-a254-1f237892c767"
      },
      "source": [
        "#run Code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_360.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:02<00:00, 45.8MB/s]\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_360.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/content/AttnGAN/code/GlobalAttention.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  sent_att                = nn.Softmax()(sentence_vs)  # batch x idf x ih x iw\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "step :  100 iters_100_time :  72.2852098941803\n",
            "step :  200 iters_100_time :  68.25555086135864\n",
            "step :  300 iters_100_time :  68.17408275604248\n",
            "step :  400 iters_100_time :  68.18635535240173\n",
            "[361/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 58.29 Time: 305.62s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  40.172231674194336\n",
            "step :  600 iters_100_time :  68.19920134544373\n",
            "step :  700 iters_100_time :  68.22087049484253\n",
            "step :  800 iters_100_time :  68.16891860961914\n",
            "[362/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 61.84 Time: 302.29s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  11.527221918106079\n",
            "step :  1000 iters_100_time :  68.22976326942444\n",
            "step :  1100 iters_100_time :  68.25257468223572\n",
            "step :  1200 iters_100_time :  68.26627278327942\n",
            "step :  1300 iters_100_time :  68.26200699806213\n",
            "[363/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 40.79 Time: 302.56s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  50.95657515525818\n",
            "step :  1500 iters_100_time :  68.29498028755188\n",
            "step :  1600 iters_100_time :  68.20111799240112\n",
            "step :  1700 iters_100_time :  68.29102730751038\n",
            "[364/600][442]\n",
            "                    Loss_D: 0.31 Loss_G: 67.40 Time: 302.46s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  22.50627303123474\n",
            "step :  1900 iters_100_time :  68.2297089099884\n",
            "step :  2000 iters_100_time :  68.22331762313843\n",
            "step :  2100 iters_100_time :  68.23460245132446\n",
            "step :  2200 iters_100_time :  68.26377153396606\n",
            "[365/600][442]\n",
            "                    Loss_D: 0.64 Loss_G: 60.61 Time: 302.53s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  61.944775342941284\n",
            "step :  2400 iters_100_time :  68.18990921974182\n",
            "step :  2500 iters_100_time :  68.32105159759521\n",
            "step :  2600 iters_100_time :  68.25651144981384\n",
            "[366/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 60.70 Time: 302.53s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  33.33129072189331\n",
            "step :  2800 iters_100_time :  68.19620037078857\n",
            "step :  2900 iters_100_time :  68.17563533782959\n",
            "step :  3000 iters_100_time :  68.2600908279419\n",
            "[367/600][442]\n",
            "                    Loss_D: 0.46 Loss_G: 55.90 Time: 302.37s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  4.695709466934204\n",
            "step :  3200 iters_100_time :  68.28761315345764\n",
            "step :  3300 iters_100_time :  68.20949935913086\n",
            "step :  3400 iters_100_time :  68.2164044380188\n",
            "step :  3500 iters_100_time :  68.29990029335022\n",
            "[368/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 52.70 Time: 302.52s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  44.296751737594604\n",
            "step :  3700 iters_100_time :  68.26793217658997\n",
            "step :  3800 iters_100_time :  68.23375201225281\n",
            "step :  3900 iters_100_time :  68.23858761787415\n",
            "[369/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 48.28 Time: 302.53s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  15.645666599273682\n",
            "step :  4100 iters_100_time :  68.24752449989319\n",
            "step :  4200 iters_100_time :  68.18865942955017\n",
            "step :  4300 iters_100_time :  68.20438694953918\n",
            "step :  4400 iters_100_time :  68.2190191745758\n",
            "[370/600][442]\n",
            "                    Loss_D: 0.72 Loss_G: 44.63 Time: 302.39s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  55.22121715545654\n",
            "step :  4600 iters_100_time :  68.13007736206055\n",
            "step :  4700 iters_100_time :  68.18507099151611\n",
            "step :  4800 iters_100_time :  68.17739939689636\n",
            "[371/600][442]\n",
            "                    Loss_D: 0.26 Loss_G: 62.84 Time: 302.34s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  26.48154640197754\n",
            "step :  5000 iters_100_time :  68.13128185272217\n",
            "step :  5100 iters_100_time :  68.17975425720215\n",
            "step :  5200 iters_100_time :  68.14691758155823\n",
            "step :  5300 iters_100_time :  68.1446647644043\n",
            "[372/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 63.02 Time: 302.08s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  65.98301005363464\n",
            "step :  5500 iters_100_time :  68.17943120002747\n",
            "step :  5600 iters_100_time :  68.27970790863037\n",
            "step :  5700 iters_100_time :  68.21912503242493\n",
            "[373/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 55.07 Time: 302.32s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  37.388970136642456\n",
            "step :  5900 iters_100_time :  68.22305846214294\n",
            "step :  6000 iters_100_time :  68.2056074142456\n",
            "step :  6100 iters_100_time :  68.22134733200073\n",
            "[374/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 55.43 Time: 302.41s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  8.830719470977783\n",
            "step :  6300 iters_100_time :  68.19542479515076\n",
            "step :  6400 iters_100_time :  68.17779207229614\n",
            "step :  6500 iters_100_time :  68.20975112915039\n",
            "step :  6600 iters_100_time :  68.2071783542633\n",
            "[375/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 83.13 Time: 302.43s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  48.3333797454834\n",
            "step :  6800 iters_100_time :  68.15690112113953\n",
            "step :  6900 iters_100_time :  68.15464663505554\n",
            "step :  7000 iters_100_time :  68.13772916793823\n",
            "[376/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 59.09 Time: 302.11s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  19.715263843536377\n",
            "step :  7200 iters_100_time :  68.1459608078003\n",
            "step :  7300 iters_100_time :  68.20852875709534\n",
            "step :  7400 iters_100_time :  68.14241003990173\n",
            "step :  7500 iters_100_time :  68.1749415397644\n",
            "[377/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 58.99 Time: 302.20s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  59.09263467788696\n",
            "step :  7700 iters_100_time :  68.1630654335022\n",
            "step :  7800 iters_100_time :  68.3124737739563\n",
            "step :  7900 iters_100_time :  68.29475712776184\n",
            "[378/600][442]\n",
            "                    Loss_D: 0.18 Loss_G: 69.61 Time: 302.42s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  30.70707607269287\n",
            "step :  8100 iters_100_time :  68.2601146697998\n",
            "step :  8200 iters_100_time :  68.22206735610962\n",
            "step :  8300 iters_100_time :  68.20925116539001\n",
            "[379/600][442]\n",
            "                    Loss_D: 2.00 Loss_G: 50.59 Time: 302.53s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.0841708183288574\n",
            "step :  8500 iters_100_time :  68.34754085540771\n",
            "step :  8600 iters_100_time :  68.19677829742432\n",
            "step :  8700 iters_100_time :  68.24505829811096\n",
            "step :  8800 iters_100_time :  68.31600856781006\n",
            "[380/600][442]\n",
            "                    Loss_D: 0.35 Loss_G: 47.24 Time: 302.83s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  41.74260640144348\n",
            "step :  9000 iters_100_time :  68.14812898635864\n",
            "step :  9100 iters_100_time :  68.19885087013245\n",
            "step :  9200 iters_100_time :  68.27971768379211\n",
            "[381/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 50.75 Time: 302.74s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  12.903075218200684\n",
            "step :  9400 iters_100_time :  68.34140062332153\n",
            "step :  9500 iters_100_time :  68.25730037689209\n",
            "step :  9600 iters_100_time :  68.25564646720886\n",
            "step :  9700 iters_100_time :  68.35056972503662\n",
            "[382/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 62.80 Time: 302.81s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  52.57705640792847\n",
            "step :  9900 iters_100_time :  68.2325394153595\n",
            "step :  10000 iters_100_time :  68.30954384803772\n",
            "step :  10100 iters_100_time :  68.26816582679749\n",
            "[383/600][442]\n",
            "                    Loss_D: 1.25 Loss_G: 48.31 Time: 302.65s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  23.783458948135376\n",
            "step :  10300 iters_100_time :  68.24193167686462\n",
            "step :  10400 iters_100_time :  68.26722550392151\n",
            "step :  10500 iters_100_time :  68.24647545814514\n",
            "step :  10600 iters_100_time :  68.25522470474243\n",
            "[384/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 43.35 Time: 302.54s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  63.59039115905762\n",
            "step :  10800 iters_100_time :  68.30747509002686\n",
            "step :  10900 iters_100_time :  68.33246803283691\n",
            "step :  11000 iters_100_time :  68.28942847251892\n",
            "[385/600][442]\n",
            "                    Loss_D: 2.00 Loss_G: 75.23 Time: 302.95s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  34.77511715888977\n",
            "step :  11200 iters_100_time :  68.31829357147217\n",
            "step :  11300 iters_100_time :  68.23641967773438\n",
            "step :  11400 iters_100_time :  68.24838709831238\n",
            "[386/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 52.21 Time: 302.70s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  6.1458258628845215\n",
            "step :  11600 iters_100_time :  68.2936098575592\n",
            "step :  11700 iters_100_time :  68.26501178741455\n",
            "step :  11800 iters_100_time :  68.23892307281494\n",
            "step :  11900 iters_100_time :  68.31910872459412\n",
            "[387/600][442]\n",
            "                    Loss_D: 0.43 Loss_G: 56.63 Time: 302.75s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  45.69961094856262\n",
            "step :  12100 iters_100_time :  68.22569727897644\n",
            "step :  12200 iters_100_time :  68.26071739196777\n",
            "step :  12300 iters_100_time :  68.26723313331604\n",
            "[388/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 50.24 Time: 302.67s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  16.862416982650757\n",
            "step :  12500 iters_100_time :  68.27360391616821\n",
            "step :  12600 iters_100_time :  68.23940825462341\n",
            "step :  12700 iters_100_time :  68.2239899635315\n",
            "step :  12800 iters_100_time :  68.28165006637573\n",
            "[389/600][442]\n",
            "                    Loss_D: 3.16 Loss_G: 103.08 Time: 302.45s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  56.51750731468201\n",
            "step :  13000 iters_100_time :  68.21284556388855\n",
            "step :  13100 iters_100_time :  68.2998218536377\n",
            "step :  13200 iters_100_time :  68.30326890945435\n",
            "[390/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 56.11 Time: 302.61s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  28.085265159606934\n",
            "step :  13400 iters_100_time :  68.302574634552\n",
            "step :  13500 iters_100_time :  68.22658205032349\n",
            "step :  13600 iters_100_time :  68.1965684890747\n",
            "step :  13700 iters_100_time :  68.25354671478271\n",
            "[391/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 44.91 Time: 302.77s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  67.63959312438965\n",
            "step :  13900 iters_100_time :  68.24148797988892\n",
            "step :  14000 iters_100_time :  68.18988537788391\n",
            "step :  14100 iters_100_time :  68.18207478523254\n",
            "[392/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 68.82 Time: 302.52s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  38.80797982215881\n",
            "step :  14300 iters_100_time :  68.22795701026917\n",
            "step :  14400 iters_100_time :  68.22576832771301\n",
            "step :  14500 iters_100_time :  68.19297099113464\n",
            "[393/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 58.24 Time: 302.35s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  10.185542821884155\n",
            "step :  14700 iters_100_time :  68.23356938362122\n",
            "step :  14800 iters_100_time :  68.23952579498291\n",
            "step :  14900 iters_100_time :  68.2062156200409\n",
            "step :  15000 iters_100_time :  68.17874574661255\n",
            "[394/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 71.84 Time: 302.40s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  49.675382137298584\n",
            "step :  15200 iters_100_time :  68.1819384098053\n",
            "step :  15300 iters_100_time :  68.2476007938385\n",
            "step :  15400 iters_100_time :  68.22527122497559\n",
            "[395/600][442]\n",
            "                    Loss_D: 0.54 Loss_G: 81.38 Time: 302.34s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  21.11902403831482\n",
            "step :  15600 iters_100_time :  68.16754603385925\n",
            "step :  15700 iters_100_time :  68.17998480796814\n",
            "step :  15800 iters_100_time :  68.23064041137695\n",
            "step :  15900 iters_100_time :  68.28988289833069\n",
            "[396/600][442]\n",
            "                    Loss_D: 0.84 Loss_G: 60.36 Time: 302.43s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  60.67045259475708\n",
            "step :  16100 iters_100_time :  68.18355393409729\n",
            "step :  16200 iters_100_time :  68.26042342185974\n",
            "step :  16300 iters_100_time :  68.20877861976624\n",
            "[397/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 52.95 Time: 302.42s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  31.97822403907776\n",
            "step :  16500 iters_100_time :  68.21617484092712\n",
            "step :  16600 iters_100_time :  68.24024224281311\n",
            "step :  16700 iters_100_time :  68.21434259414673\n",
            "[398/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 58.79 Time: 302.44s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  3.3046555519104004\n",
            "step :  16900 iters_100_time :  68.27857899665833\n",
            "step :  17000 iters_100_time :  68.22922134399414\n",
            "step :  17100 iters_100_time :  68.2463800907135\n",
            "step :  17200 iters_100_time :  68.1794171333313\n",
            "[399/600][442]\n",
            "                    Loss_D: 0.38 Loss_G: 44.38 Time: 302.46s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  42.940134048461914\n",
            "step :  17400 iters_100_time :  68.21358013153076\n",
            "step :  17500 iters_100_time :  68.35738277435303\n",
            "step :  17600 iters_100_time :  68.18877363204956\n",
            "[400/600][442]\n",
            "                    Loss_D: 0.44 Loss_G: 52.97 Time: 302.54s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  14.381623983383179\n",
            "step :  17800 iters_100_time :  68.24911570549011\n",
            "step :  17900 iters_100_time :  68.20062923431396\n",
            "step :  18000 iters_100_time :  68.27838015556335\n",
            "step :  18100 iters_100_time :  68.21083521842957\n",
            "[401/600][442]\n",
            "                    Loss_D: 0.97 Loss_G: 38.52 Time: 302.77s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  53.82834506034851\n",
            "step :  18300 iters_100_time :  68.21385622024536\n",
            "step :  18400 iters_100_time :  68.24122047424316\n",
            "step :  18500 iters_100_time :  68.26457858085632\n",
            "[402/600][442]\n",
            "                    Loss_D: 0.31 Loss_G: 51.65 Time: 302.51s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  25.103803873062134\n",
            "step :  18700 iters_100_time :  68.24733281135559\n",
            "step :  18800 iters_100_time :  68.20182919502258\n",
            "step :  18900 iters_100_time :  68.28395676612854\n",
            "step :  19000 iters_100_time :  68.2549729347229\n",
            "[403/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 60.74 Time: 302.47s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  64.7939805984497\n",
            "step :  19200 iters_100_time :  68.24838376045227\n",
            "step :  19300 iters_100_time :  68.22353839874268\n",
            "step :  19400 iters_100_time :  68.29358053207397\n",
            "[404/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 55.86 Time: 302.56s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  36.10489773750305\n",
            "step :  19600 iters_100_time :  68.26513886451721\n",
            "step :  19700 iters_100_time :  68.30589699745178\n",
            "step :  19800 iters_100_time :  68.27098774909973\n",
            "[405/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 54.64 Time: 302.60s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  7.440783500671387\n",
            "step :  20000 iters_100_time :  68.35749244689941\n",
            "step :  20100 iters_100_time :  68.26644229888916\n",
            "step :  20200 iters_100_time :  68.27738285064697\n",
            "step :  20300 iters_100_time :  68.25527167320251\n",
            "[406/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 59.95 Time: 302.67s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  46.99460983276367\n",
            "step :  20500 iters_100_time :  68.27750825881958\n",
            "step :  20600 iters_100_time :  68.29055643081665\n",
            "step :  20700 iters_100_time :  68.2728624343872\n",
            "[407/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 47.91 Time: 302.69s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  18.322275638580322\n",
            "step :  20900 iters_100_time :  68.29490327835083\n",
            "step :  21000 iters_100_time :  68.3088002204895\n",
            "step :  21100 iters_100_time :  68.33022880554199\n",
            "step :  21200 iters_100_time :  68.25197196006775\n",
            "[408/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 62.08 Time: 302.72s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  57.820083141326904\n",
            "step :  21400 iters_100_time :  68.1658308506012\n",
            "step :  21500 iters_100_time :  68.12234139442444\n",
            "step :  21600 iters_100_time :  68.19316720962524\n",
            "[409/600][442]\n",
            "                    Loss_D: 0.32 Loss_G: 62.64 Time: 302.05s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  29.16583752632141\n",
            "step :  21800 iters_100_time :  68.193598985672\n",
            "step :  21900 iters_100_time :  68.2785336971283\n",
            "step :  22000 iters_100_time :  68.29251003265381\n",
            "step :  22100 iters_100_time :  68.28732872009277\n",
            "[410/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 58.44 Time: 302.50s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  69.07885932922363\n",
            "step :  22300 iters_100_time :  68.27168774604797\n",
            "step :  22400 iters_100_time :  68.30956149101257\n",
            "step :  22500 iters_100_time :  68.29660630226135\n",
            "[411/600][442]\n",
            "                    Loss_D: 2.19 Loss_G: 38.22 Time: 302.97s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  40.23467659950256\n",
            "step :  22700 iters_100_time :  68.32129740715027\n",
            "step :  22800 iters_100_time :  68.29410314559937\n",
            "step :  22900 iters_100_time :  68.21595287322998\n",
            "[412/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 54.94 Time: 302.53s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  11.366847038269043\n",
            "step :  23100 iters_100_time :  68.16605377197266\n",
            "step :  23200 iters_100_time :  68.13115692138672\n",
            "step :  23300 iters_100_time :  68.11136388778687\n",
            "step :  23400 iters_100_time :  68.35944724082947\n",
            "[413/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 58.35 Time: 302.21s\n",
            "num_batches :  442\n",
            "step :  23500 iters_100_time :  50.98822283744812\n",
            "step :  23600 iters_100_time :  68.2601158618927\n",
            "step :  23700 iters_100_time :  68.17096877098083\n",
            "step :  23800 iters_100_time :  68.16187572479248\n",
            "[414/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 74.21 Time: 302.17s\n",
            "num_batches :  442\n",
            "step :  23900 iters_100_time :  22.429532289505005\n",
            "step :  24000 iters_100_time :  68.31080317497253\n",
            "step :  24100 iters_100_time :  68.36494898796082\n",
            "step :  24200 iters_100_time :  68.37550520896912\n",
            "step :  24300 iters_100_time :  68.36932897567749\n",
            "[415/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 63.09 Time: 302.93s\n",
            "num_batches :  442\n",
            "step :  24400 iters_100_time :  61.88762617111206\n",
            "step :  24500 iters_100_time :  68.15109324455261\n",
            "step :  24600 iters_100_time :  68.23365139961243\n",
            "step :  24700 iters_100_time :  68.3490698337555\n",
            "[416/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 50.45 Time: 302.41s\n",
            "num_batches :  442\n",
            "step :  24800 iters_100_time :  33.42108368873596\n",
            "step :  24900 iters_100_time :  68.39345335960388\n",
            "step :  25000 iters_100_time :  68.37475800514221\n",
            "step :  25000 iters_5000_time :  170.18940806388855\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 140, in <module>\n",
            "    algo.train()\n",
            "  File \"/content/AttnGAN/code/trainer.py\", line 346, in train\n",
            "    captions, cap_lens, epoch, name='average')\n",
            "  File \"/content/AttnGAN/code/trainer.py\", line 203, in save_img_results\n",
            "    attn_maps, att_sze, lr_imgs=lr_img)\n",
            "  File \"/content/AttnGAN/code/miscc/utils.py\", line 109, in build_super_images\n",
            "    drawCaption(text_convas, captions, ixtoword, vis_size)\n",
            "  File \"/content/AttnGAN/code/miscc/utils.py\", line 37, in drawCaption\n",
            "    fnt = ImageFont.truetype('Pillow/Tests/fonts/FreeMono.ttf', 50)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFont.py\", line 642, in truetype\n",
            "    return freetype(font)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFont.py\", line 639, in freetype\n",
            "    return FreeTypeFont(font, size, index, encoding, layout_engine)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/ImageFont.py\", line 188, in __init__\n",
            "    font, size, index, encoding, layout_engine=layout_engine\n",
            "OSError: cannot open resource\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JqjTMflgFjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}