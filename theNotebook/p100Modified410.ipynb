{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p100Modified410.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKMXRp_ZY4su",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "c73a3d6b-537d-4315-edc4-40394f78f202"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jun 28 19:25:15 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jb2RUyCra1Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/')\n",
        "!rm -r sample_data\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of9kI30fbZWC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "4f9601cf-22a4-43d2-d4ed-2babd61793fa"
      },
      "source": [
        "#clone repo AttnGAN\n",
        "os.chdir('/content/')\n",
        "!rm -r AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'AttnGAN': No such file or directory\n",
            "Cloning into 'AttnGAN'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Total 291 (delta 0), reused 0 (delta 0), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (291/291), 36.76 MiB | 37.75 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mXQOOMKfCQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "84938cd7-2d51-466f-9106-f4ebca282502"
      },
      "source": [
        "# Download captionts filenames and classes info\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-28 19:52:27--  https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.216.100, 173.194.216.113, 173.194.216.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.216.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rddo9177608vr08k2aq7feqcubba3ki7/1593373950000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-06-28 19:52:56--  https://doc-0o-9g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rddo9177608vr08k2aq7feqcubba3ki7/1593373950000/09657060183789739732/*/1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ?e=download\n",
            "Resolving doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)... 172.217.193.132, 2607:f8b0:400c:c03::84\n",
            "Connecting to doc-0o-9g-docs.googleusercontent.com (doc-0o-9g-docs.googleusercontent.com)|172.217.193.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘birds.zip’\n",
            "\n",
            "birds.zip               [ <=>                ]   6.19M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-06-28 19:52:57 (160 MB/s) - ‘birds.zip’ saved [6488322]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2o_gljRfCG4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "a136adf1-d9de-40f8-b97d-0d6123bda9df"
      },
      "source": [
        "# Download Cub Datatset\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!wget http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-28 19:53:02--  http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
            "Resolving www.vision.caltech.edu (www.vision.caltech.edu)... 34.208.54.77\n",
            "Connecting to www.vision.caltech.edu (www.vision.caltech.edu)|34.208.54.77|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1150585339 (1.1G) [application/x-tar]\n",
            "Saving to: ‘CUB_200_2011.tgz’\n",
            "\n",
            "CUB_200_2011.tgz    100%[===================>]   1.07G  14.8MB/s    in 1m 59s  \n",
            "\n",
            "2020-06-28 19:55:01 (9.22 MB/s) - ‘CUB_200_2011.tgz’ saved [1150585339/1150585339]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uapMBGvvfB-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "162ec6aa-9dd4-4ffc-8ff1-a19f11ded2b5"
      },
      "source": [
        "#Dwonload files text encoder and image encoder\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "# #Move Models text and image encoder to their /content/\n",
        "!mv  /content/CUB-Attn-GAN/theModel/text_encoder599.pth  /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "\n",
        "!rm -r CUB-Attn-GAN "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'bird/': No such file or directory\n",
            "Cloning into 'CUB-Attn-GAN'...\n",
            "remote: Enumerating objects: 502, done.\u001b[K\n",
            "remote: Total 502 (delta 0), reused 0 (delta 0), pack-reused 502\u001b[K\n",
            "Receiving objects: 100% (502/502), 262.95 MiB | 44.56 MiB/s, done.\n",
            "Resolving deltas: 100% (279/279), done.\n",
            "Checking out files: 100% (76/76), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXRAZMSDfQPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download Pillow Font\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKY0AQ4ZfdZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netG_epoch_410.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhFfBIDqfza1",
        "colab_type": "text"
      },
      "source": [
        "# ========================================================"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbCDidIKffyf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "64796775-c9fb-44e4-d935-8b76e7a8f4af"
      },
      "source": [
        "#Move code files to their Locations\n",
        "os.chdir('/content')\n",
        "!rm -r Modified_CUB_Attn_GAN/\n",
        "!git clone https://github.com/ammarnasr/Modified_CUB_Attn_GAN.git\n",
        "\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/config.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/utils.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/datasets.py                  /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/GlobalAttention.py          /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/model.py                   /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/losses.py                 /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/trainer.py               /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/bird_attn2.yml          /content/AttnGAN/code/cfg/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Modified_CUB_Attn_GAN'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/114)\u001b[K\rremote: Counting objects:   1% (2/114)\u001b[K\rremote: Counting objects:   2% (3/114)\u001b[K\rremote: Counting objects:   3% (4/114)\u001b[K\rremote: Counting objects:   4% (5/114)\u001b[K\rremote: Counting objects:   5% (6/114)\u001b[K\rremote: Counting objects:   6% (7/114)\u001b[K\rremote: Counting objects:   7% (8/114)\u001b[K\rremote: Counting objects:   8% (10/114)\u001b[K\rremote: Counting objects:   9% (11/114)\u001b[K\rremote: Counting objects:  10% (12/114)\u001b[K\rremote: Counting objects:  11% (13/114)\u001b[K\rremote: Counting objects:  12% (14/114)\u001b[K\rremote: Counting objects:  13% (15/114)\u001b[K\rremote: Counting objects:  14% (16/114)\u001b[K\rremote: Counting objects:  15% (18/114)\u001b[K\rremote: Counting objects:  16% (19/114)\u001b[K\rremote: Counting objects:  17% (20/114)\u001b[K\rremote: Counting objects:  18% (21/114)\u001b[K\rremote: Counting objects:  19% (22/114)\u001b[K\rremote: Counting objects:  20% (23/114)\u001b[K\rremote: Counting objects:  21% (24/114)\u001b[K\rremote: Counting objects:  22% (26/114)\u001b[K\rremote: Counting objects:  23% (27/114)\u001b[K\rremote: Counting objects:  24% (28/114)\u001b[K\rremote: Counting objects:  25% (29/114)\u001b[K\rremote: Counting objects:  26% (30/114)\u001b[K\rremote: Counting objects:  27% (31/114)\u001b[K\rremote: Counting objects:  28% (32/114)\u001b[K\rremote: Counting objects:  29% (34/114)\u001b[K\rremote: Counting objects:  30% (35/114)\u001b[K\rremote: Counting objects:  31% (36/114)\u001b[K\rremote: Counting objects:  32% (37/114)\u001b[K\rremote: Counting objects:  33% (38/114)\u001b[K\rremote: Counting objects:  34% (39/114)\u001b[K\rremote: Counting objects:  35% (40/114)\u001b[K\rremote: Counting objects:  36% (42/114)\u001b[K\rremote: Counting objects:  37% (43/114)\u001b[K\rremote: Counting objects:  38% (44/114)\u001b[K\rremote: Counting objects:  39% (45/114)\u001b[K\rremote: Counting objects:  40% (46/114)\u001b[K\rremote: Counting objects:  41% (47/114)\u001b[K\rremote: Counting objects:  42% (48/114)\u001b[K\rremote: Counting objects:  43% (50/114)\u001b[K\rremote: Counting objects:  44% (51/114)\u001b[K\rremote: Counting objects:  45% (52/114)\u001b[K\rremote: Counting objects:  46% (53/114)\u001b[K\rremote: Counting objects:  47% (54/114)\u001b[K\rremote: Counting objects:  48% (55/114)\u001b[K\rremote: Counting objects:  49% (56/114)\u001b[K\rremote: Counting objects:  50% (57/114)\u001b[K\rremote: Counting objects:  51% (59/114)\u001b[K\rremote: Counting objects:  52% (60/114)\u001b[K\rremote: Counting objects:  53% (61/114)\u001b[K\rremote: Counting objects:  54% (62/114)\u001b[K\rremote: Counting objects:  55% (63/114)\u001b[K\rremote: Counting objects:  56% (64/114)\u001b[K\rremote: Counting objects:  57% (65/114)\u001b[K\rremote: Counting objects:  58% (67/114)\u001b[K\rremote: Counting objects:  59% (68/114)\u001b[K\rremote: Counting objects:  60% (69/114)\u001b[K\rremote: Counting objects:  61% (70/114)\u001b[K\rremote: Counting objects:  62% (71/114)\u001b[K\rremote: Counting objects:  63% (72/114)\u001b[K\rremote: Counting objects:  64% (73/114)\u001b[K\rremote: Counting objects:  65% (75/114)\u001b[K\rremote: Counting objects:  66% (76/114)\u001b[K\rremote: Counting objects:  67% (77/114)\u001b[K\rremote: Counting objects:  68% (78/114)\u001b[K\rremote: Counting objects:  69% (79/114)\u001b[K\rremote: Counting objects:  70% (80/114)\u001b[K\rremote: Counting objects:  71% (81/114)\u001b[K\rremote: Counting objects:  72% (83/114)\u001b[K\rremote: Counting objects:  73% (84/114)\u001b[K\rremote: Counting objects:  74% (85/114)\u001b[K\rremote: Counting objects:  75% (86/114)\u001b[K\rremote: Counting objects:  76% (87/114)\u001b[K\rremote: Counting objects:  77% (88/114)\u001b[K\rremote: Counting objects:  78% (89/114)\u001b[K\rremote: Counting objects:  79% (91/114)\u001b[K\rremote: Counting objects:  80% (92/114)\u001b[K\rremote: Counting objects:  81% (93/114)\u001b[K\rremote: Counting objects:  82% (94/114)\u001b[K\rremote: Counting objects:  83% (95/114)\u001b[K\rremote: Counting objects:  84% (96/114)\u001b[K\rremote: Counting objects:  85% (97/114)\u001b[K\rremote: Counting objects:  86% (99/114)\u001b[K\rremote: Counting objects:  87% (100/114)\u001b[K\rremote: Counting objects:  88% (101/114)\u001b[K\rremote: Counting objects:  89% (102/114)\u001b[K\rremote: Counting objects:  90% (103/114)\u001b[K\rremote: Counting objects:  91% (104/114)\u001b[K\rremote: Counting objects:  92% (105/114)\u001b[K\rremote: Counting objects:  93% (107/114)\u001b[K\rremote: Counting objects:  94% (108/114)\u001b[K\rremote: Counting objects:  95% (109/114)\u001b[K\rremote: Counting objects:  96% (110/114)\u001b[K\rremote: Counting objects:  97% (111/114)\u001b[K\rremote: Counting objects:  98% (112/114)\u001b[K\rremote: Counting objects:  99% (113/114)\u001b[K\rremote: Counting objects: 100% (114/114)\u001b[K\rremote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects:   1% (1/79)\u001b[K\rremote: Compressing objects:   2% (2/79)\u001b[K\rremote: Compressing objects:   3% (3/79)\u001b[K\rremote: Compressing objects:   5% (4/79)\u001b[K\rremote: Compressing objects:   6% (5/79)\u001b[K\rremote: Compressing objects:   7% (6/79)\u001b[K\rremote: Compressing objects:   8% (7/79)\u001b[K\rremote: Compressing objects:  10% (8/79)\u001b[K\rremote: Compressing objects:  11% (9/79)\u001b[K\rremote: Compressing objects:  12% (10/79)\u001b[K\rremote: Compressing objects:  13% (11/79)\u001b[K\rremote: Compressing objects:  15% (12/79)\u001b[K\rremote: Compressing objects:  16% (13/79)\u001b[K\rremote: Compressing objects:  17% (14/79)\u001b[K\rremote: Compressing objects:  18% (15/79)\u001b[K\rremote: Compressing objects:  20% (16/79)\u001b[K\rremote: Compressing objects:  21% (17/79)\u001b[K\rremote: Compressing objects:  22% (18/79)\u001b[K\rremote: Compressing objects:  24% (19/79)\u001b[K\rremote: Compressing objects:  25% (20/79)\u001b[K\rremote: Compressing objects:  26% (21/79)\u001b[K\rremote: Compressing objects:  27% (22/79)\u001b[K\rremote: Compressing objects:  29% (23/79)\u001b[K\rremote: Compressing objects:  30% (24/79)\u001b[K\rremote: Compressing objects:  31% (25/79)\u001b[K\rremote: Compressing objects:  32% (26/79)\u001b[K\rremote: Compressing objects:  34% (27/79)\u001b[K\rremote: Compressing objects:  35% (28/79)\u001b[K\rremote: Compressing objects:  36% (29/79)\u001b[K\rremote: Compressing objects:  37% (30/79)\u001b[K\rremote: Compressing objects:  39% (31/79)\u001b[K\rremote: Compressing objects:  40% (32/79)\u001b[K\rremote: Compressing objects:  41% (33/79)\u001b[K\rremote: Compressing objects:  43% (34/79)\u001b[K\rremote: Compressing objects:  44% (35/79)\u001b[K\rremote: Compressing objects:  45% (36/79)\u001b[K\rremote: Compressing objects:  46% (37/79)\u001b[K\rremote: Compressing objects:  48% (38/79)\u001b[K\rremote: Compressing objects:  49% (39/79)\u001b[K\rremote: Compressing objects:  50% (40/79)\u001b[K\rremote: Compressing objects:  51% (41/79)\u001b[K\rremote: Compressing objects:  53% (42/79)\u001b[K\rremote: Compressing objects:  54% (43/79)\u001b[K\rremote: Compressing objects:  55% (44/79)\u001b[K\rremote: Compressing objects:  56% (45/79)\u001b[K\rremote: Compressing objects:  58% (46/79)\u001b[K\rremote: Compressing objects:  59% (47/79)\u001b[K\rremote: Compressing objects:  60% (48/79)\u001b[K\rremote: Compressing objects:  62% (49/79)\u001b[K\rremote: Compressing objects:  63% (50/79)\u001b[K\rremote: Compressing objects:  64% (51/79)\u001b[K\rremote: Compressing objects:  65% (52/79)\u001b[K\rremote: Compressing objects:  67% (53/79)\u001b[K\rremote: Compressing objects:  68% (54/79)\u001b[K\rremote: Compressing objects:  69% (55/79)\u001b[K\rremote: Compressing objects:  70% (56/79)\u001b[K\rremote: Compressing objects:  72% (57/79)\u001b[K\rremote: Compressing objects:  73% (58/79)\u001b[K\rremote: Compressing objects:  74% (59/79)\u001b[K\rremote: Compressing objects:  75% (60/79)\u001b[K\rremote: Compressing objects:  77% (61/79)\u001b[K\rremote: Compressing objects:  78% (62/79)\u001b[K\rremote: Compressing objects:  79% (63/79)\u001b[K\rremote: Compressing objects:  81% (64/79)\u001b[K\rremote: Compressing objects:  82% (65/79)\u001b[K\rremote: Compressing objects:  83% (66/79)\u001b[K\rremote: Compressing objects:  84% (67/79)\u001b[K\rremote: Compressing objects:  86% (68/79)\u001b[K\rremote: Compressing objects:  87% (69/79)\u001b[K\rremote: Compressing objects:  88% (70/79)\u001b[K\rremote: Compressing objects:  89% (71/79)\u001b[K\rremote: Compressing objects:  91% (72/79)\u001b[K\rremote: Compressing objects:  92% (73/79)\u001b[K\rremote: Compressing objects:  93% (74/79)\u001b[K\rremote: Compressing objects:  94% (75/79)\u001b[K\rremote: Compressing objects:  96% (76/79)\u001b[K\rremote: Compressing objects:  97% (77/79)\u001b[K\rremote: Compressing objects:  98% (78/79)\u001b[K\rremote: Compressing objects: 100% (79/79)\u001b[K\rremote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "Receiving objects:   0% (1/114)   \rReceiving objects:   1% (2/114)   \rReceiving objects:   2% (3/114)   \rReceiving objects:   3% (4/114)   \rReceiving objects:   4% (5/114)   \rReceiving objects:   5% (6/114)   \rReceiving objects:   6% (7/114)   \rReceiving objects:   7% (8/114)   \rReceiving objects:   8% (10/114)   \rReceiving objects:   9% (11/114)   \rReceiving objects:  10% (12/114)   \rReceiving objects:  11% (13/114)   \rReceiving objects:  12% (14/114)   \rReceiving objects:  13% (15/114)   \rReceiving objects:  14% (16/114)   \rReceiving objects:  15% (18/114)   \rReceiving objects:  16% (19/114)   \rReceiving objects:  17% (20/114)   \rReceiving objects:  18% (21/114)   \rReceiving objects:  19% (22/114)   \rReceiving objects:  20% (23/114)   \rReceiving objects:  21% (24/114)   \rReceiving objects:  22% (26/114)   \rReceiving objects:  23% (27/114)   \rReceiving objects:  24% (28/114)   \rReceiving objects:  25% (29/114)   \rReceiving objects:  26% (30/114)   \rReceiving objects:  27% (31/114)   \rReceiving objects:  28% (32/114)   \rReceiving objects:  29% (34/114)   \rReceiving objects:  30% (35/114)   \rReceiving objects:  31% (36/114)   \rReceiving objects:  32% (37/114)   \rReceiving objects:  33% (38/114)   \rReceiving objects:  34% (39/114)   \rReceiving objects:  35% (40/114)   \rReceiving objects:  36% (42/114)   \rReceiving objects:  37% (43/114)   \rReceiving objects:  38% (44/114)   \rReceiving objects:  39% (45/114)   \rReceiving objects:  40% (46/114)   \rReceiving objects:  41% (47/114)   \rReceiving objects:  42% (48/114)   \rReceiving objects:  43% (50/114)   \rReceiving objects:  44% (51/114)   \rReceiving objects:  45% (52/114)   \rReceiving objects:  46% (53/114)   \rReceiving objects:  47% (54/114)   \rReceiving objects:  48% (55/114)   \rReceiving objects:  49% (56/114)   \rReceiving objects:  50% (57/114)   \rremote: Total 114 (delta 46), reused 98 (delta 33), pack-reused 0\u001b[K\n",
            "Receiving objects:  51% (59/114)   \rReceiving objects:  52% (60/114)   \rReceiving objects:  53% (61/114)   \rReceiving objects:  54% (62/114)   \rReceiving objects:  55% (63/114)   \rReceiving objects:  56% (64/114)   \rReceiving objects:  57% (65/114)   \rReceiving objects:  58% (67/114)   \rReceiving objects:  59% (68/114)   \rReceiving objects:  60% (69/114)   \rReceiving objects:  61% (70/114)   \rReceiving objects:  62% (71/114)   \rReceiving objects:  63% (72/114)   \rReceiving objects:  64% (73/114)   \rReceiving objects:  65% (75/114)   \rReceiving objects:  66% (76/114)   \rReceiving objects:  67% (77/114)   \rReceiving objects:  68% (78/114)   \rReceiving objects:  69% (79/114)   \rReceiving objects:  70% (80/114)   \rReceiving objects:  71% (81/114)   \rReceiving objects:  72% (83/114)   \rReceiving objects:  73% (84/114)   \rReceiving objects:  74% (85/114)   \rReceiving objects:  75% (86/114)   \rReceiving objects:  76% (87/114)   \rReceiving objects:  77% (88/114)   \rReceiving objects:  78% (89/114)   \rReceiving objects:  79% (91/114)   \rReceiving objects:  80% (92/114)   \rReceiving objects:  81% (93/114)   \rReceiving objects:  82% (94/114)   \rReceiving objects:  83% (95/114)   \rReceiving objects:  84% (96/114)   \rReceiving objects:  85% (97/114)   \rReceiving objects:  86% (99/114)   \rReceiving objects:  87% (100/114)   \rReceiving objects:  88% (101/114)   \rReceiving objects:  89% (102/114)   \rReceiving objects:  90% (103/114)   \rReceiving objects:  91% (104/114)   \rReceiving objects:  92% (105/114)   \rReceiving objects:  93% (107/114)   \rReceiving objects:  94% (108/114)   \rReceiving objects:  95% (109/114)   \rReceiving objects:  96% (110/114)   \rReceiving objects:  97% (111/114)   \rReceiving objects:  98% (112/114)   \rReceiving objects:  99% (113/114)   \rReceiving objects: 100% (114/114)   \rReceiving objects: 100% (114/114), 70.87 KiB | 7.09 MiB/s, done.\n",
            "Resolving deltas:   0% (0/46)   \rResolving deltas:  36% (17/46)   \rResolving deltas:  39% (18/46)   \rResolving deltas:  52% (24/46)   \rResolving deltas:  60% (28/46)   \rResolving deltas:  65% (30/46)   \rResolving deltas:  67% (31/46)   \rResolving deltas:  71% (33/46)   \rResolving deltas:  73% (34/46)   \rResolving deltas:  76% (35/46)   \rResolving deltas:  82% (38/46)   \rResolving deltas:  84% (39/46)   \rResolving deltas: 100% (46/46)   \rResolving deltas: 100% (46/46), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhS0oGMFf3Vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5fc70a8c-36ef-43a6-dbaa-ebfa9dc6689e"
      },
      "source": [
        "#run Code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_410.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_410.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/content/AttnGAN/code/GlobalAttention.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  sent_att                = nn.Softmax()(sentence_vs)  # batch x idf x ih x iw\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "step :  100 iters_100_time :  72.06103849411011\n",
            "step :  200 iters_100_time :  68.33851528167725\n",
            "step :  300 iters_100_time :  68.33535838127136\n",
            "step :  400 iters_100_time :  68.37083435058594\n",
            "[411/600][442]\n",
            "                    Loss_D: 0.35 Loss_G: 41.31 Time: 305.90s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  40.240328788757324\n",
            "step :  600 iters_100_time :  68.27359986305237\n",
            "step :  700 iters_100_time :  68.30496382713318\n",
            "step :  800 iters_100_time :  68.30627179145813\n",
            "[412/600][442]\n",
            "                    Loss_D: 0.38 Loss_G: 59.99 Time: 302.91s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  11.392925262451172\n",
            "step :  1000 iters_100_time :  68.26479053497314\n",
            "step :  1100 iters_100_time :  68.29733204841614\n",
            "step :  1200 iters_100_time :  68.24788784980774\n",
            "step :  1300 iters_100_time :  68.32829475402832\n",
            "[413/600][442]\n",
            "                    Loss_D: 0.25 Loss_G: 58.89 Time: 302.60s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  51.14889168739319\n",
            "step :  1500 iters_100_time :  68.40449380874634\n",
            "step :  1600 iters_100_time :  68.33589506149292\n",
            "step :  1700 iters_100_time :  68.36917424201965\n",
            "[414/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 66.34 Time: 302.99s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  22.411696910858154\n",
            "step :  1900 iters_100_time :  68.31869149208069\n",
            "step :  2000 iters_100_time :  68.37117052078247\n",
            "step :  2100 iters_100_time :  68.38237595558167\n",
            "step :  2200 iters_100_time :  68.36695528030396\n",
            "[415/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 56.05 Time: 302.99s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  62.09131741523743\n",
            "step :  2400 iters_100_time :  68.3129210472107\n",
            "step :  2500 iters_100_time :  68.39709854125977\n",
            "step :  2600 iters_100_time :  68.336923122406\n",
            "[416/600][442]\n",
            "                    Loss_D: 1.06 Loss_G: 67.45 Time: 302.95s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  33.45103859901428\n",
            "step :  2800 iters_100_time :  68.33626389503479\n",
            "step :  2900 iters_100_time :  68.34049701690674\n",
            "step :  3000 iters_100_time :  68.35733914375305\n",
            "[417/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 71.44 Time: 303.03s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  4.708753347396851\n",
            "step :  3200 iters_100_time :  68.37386465072632\n",
            "step :  3300 iters_100_time :  68.39131212234497\n",
            "step :  3400 iters_100_time :  68.32507586479187\n",
            "step :  3500 iters_100_time :  68.36223673820496\n",
            "[418/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 68.01 Time: 303.03s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  44.299471855163574\n",
            "step :  3700 iters_100_time :  68.38925123214722\n",
            "step :  3800 iters_100_time :  68.36098384857178\n",
            "step :  3900 iters_100_time :  68.39076828956604\n",
            "[419/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 55.75 Time: 303.06s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  15.643765211105347\n",
            "step :  4100 iters_100_time :  68.35719799995422\n",
            "step :  4200 iters_100_time :  68.32957935333252\n",
            "step :  4300 iters_100_time :  68.32026791572571\n",
            "step :  4400 iters_100_time :  68.36739945411682\n",
            "[420/600][442]\n",
            "                    Loss_D: 0.74 Loss_G: 58.48 Time: 302.98s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  55.55090808868408\n",
            "step :  4600 iters_100_time :  68.36570739746094\n",
            "step :  4700 iters_100_time :  68.35010933876038\n",
            "step :  4800 iters_100_time :  68.33362698554993\n",
            "[421/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 39.94 Time: 303.29s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  26.41279172897339\n",
            "step :  5000 iters_100_time :  68.50276160240173\n",
            "step :  5100 iters_100_time :  68.31825089454651\n",
            "step :  5200 iters_100_time :  68.32725882530212\n",
            "step :  5300 iters_100_time :  68.34161019325256\n",
            "[422/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 65.98 Time: 302.95s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  66.23157119750977\n",
            "step :  5500 iters_100_time :  68.32275581359863\n",
            "step :  5600 iters_100_time :  68.32948541641235\n",
            "step :  5700 iters_100_time :  68.32103753089905\n",
            "[423/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 46.13 Time: 302.91s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  37.3089656829834\n",
            "step :  5900 iters_100_time :  68.33008241653442\n",
            "step :  6000 iters_100_time :  68.41955518722534\n",
            "step :  6100 iters_100_time :  68.45376873016357\n",
            "[424/600][442]\n",
            "                    Loss_D: 1.25 Loss_G: 78.33 Time: 302.91s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  8.713498592376709\n",
            "step :  6300 iters_100_time :  68.37238383293152\n",
            "step :  6400 iters_100_time :  68.34413456916809\n",
            "step :  6500 iters_100_time :  68.35505771636963\n",
            "step :  6600 iters_100_time :  68.39691662788391\n",
            "[425/600][442]\n",
            "                    Loss_D: 1.49 Loss_G: 49.72 Time: 303.02s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  48.47205686569214\n",
            "step :  6800 iters_100_time :  68.41737008094788\n",
            "step :  6900 iters_100_time :  68.38990807533264\n",
            "step :  7000 iters_100_time :  68.42479085922241\n",
            "[426/600][442]\n",
            "                    Loss_D: 1.68 Loss_G: 75.37 Time: 303.33s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  19.818310976028442\n",
            "step :  7200 iters_100_time :  68.4974148273468\n",
            "step :  7300 iters_100_time :  68.38261461257935\n",
            "step :  7400 iters_100_time :  68.41295313835144\n",
            "step :  7500 iters_100_time :  68.41220450401306\n",
            "[427/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 58.06 Time: 303.40s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  59.46031475067139\n",
            "step :  7700 iters_100_time :  68.53588676452637\n",
            "step :  7800 iters_100_time :  68.43201303482056\n",
            "step :  7900 iters_100_time :  68.45636463165283\n",
            "[428/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 70.17 Time: 303.49s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  30.72826910018921\n",
            "step :  8100 iters_100_time :  68.41988611221313\n",
            "step :  8200 iters_100_time :  68.50307536125183\n",
            "step :  8300 iters_100_time :  68.43896698951721\n",
            "[429/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 71.47 Time: 303.38s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.005232095718384\n",
            "step :  8500 iters_100_time :  68.34596681594849\n",
            "step :  8600 iters_100_time :  68.42147779464722\n",
            "step :  8700 iters_100_time :  68.4167103767395\n",
            "step :  8800 iters_100_time :  68.3591845035553\n",
            "[430/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 51.85 Time: 303.18s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  41.800390005111694\n",
            "step :  9000 iters_100_time :  68.38776779174805\n",
            "step :  9100 iters_100_time :  68.50657033920288\n",
            "step :  9200 iters_100_time :  68.40463376045227\n",
            "[431/600][442]\n",
            "                    Loss_D: 0.56 Loss_G: 53.80 Time: 303.55s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  13.000697374343872\n",
            "step :  9400 iters_100_time :  68.46627116203308\n",
            "step :  9500 iters_100_time :  68.45908236503601\n",
            "step :  9600 iters_100_time :  68.45141744613647\n",
            "step :  9700 iters_100_time :  68.45323896408081\n",
            "[432/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 55.22 Time: 303.55s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  52.54434299468994\n",
            "step :  9900 iters_100_time :  68.37067317962646\n",
            "step :  10000 iters_100_time :  68.44628953933716\n",
            "step :  10100 iters_100_time :  68.43108987808228\n",
            "[433/600][442]\n",
            "                    Loss_D: 1.05 Loss_G: 54.36 Time: 303.32s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  24.049164056777954\n",
            "step :  10300 iters_100_time :  68.4948992729187\n",
            "step :  10400 iters_100_time :  68.51071619987488\n",
            "step :  10500 iters_100_time :  68.53357577323914\n",
            "step :  10600 iters_100_time :  68.50527477264404\n",
            "[434/600][442]\n",
            "                    Loss_D: 1.65 Loss_G: 58.18 Time: 303.85s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  63.57360219955444\n",
            "step :  10800 iters_100_time :  68.39714574813843\n",
            "step :  10900 iters_100_time :  68.44573664665222\n",
            "step :  11000 iters_100_time :  68.43400001525879\n",
            "[435/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 76.62 Time: 303.37s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  34.95321798324585\n",
            "step :  11200 iters_100_time :  68.55089139938354\n",
            "step :  11300 iters_100_time :  68.49649620056152\n",
            "step :  11400 iters_100_time :  68.46966290473938\n",
            "[436/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 50.73 Time: 303.71s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  6.0737080574035645\n",
            "step :  11600 iters_100_time :  68.44271898269653\n",
            "step :  11700 iters_100_time :  68.38207840919495\n",
            "step :  11800 iters_100_time :  68.41569328308105\n",
            "step :  11900 iters_100_time :  68.40562009811401\n",
            "[437/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 61.94 Time: 303.27s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  45.72973299026489\n",
            "step :  12100 iters_100_time :  68.49678587913513\n",
            "step :  12200 iters_100_time :  68.49060392379761\n",
            "step :  12300 iters_100_time :  68.6306676864624\n",
            "[438/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 59.51 Time: 303.87s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  17.124849319458008\n",
            "step :  12500 iters_100_time :  68.52307081222534\n",
            "step :  12600 iters_100_time :  68.53111124038696\n",
            "step :  12700 iters_100_time :  68.52196598052979\n",
            "step :  12800 iters_100_time :  68.4093668460846\n",
            "[439/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 74.61 Time: 303.75s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  56.6257050037384\n",
            "step :  13000 iters_100_time :  68.44940948486328\n",
            "step :  13100 iters_100_time :  68.44641470909119\n",
            "step :  13200 iters_100_time :  68.47031354904175\n",
            "[440/600][442]\n",
            "                    Loss_D: 0.24 Loss_G: 60.94 Time: 303.33s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  28.230883359909058\n",
            "step :  13400 iters_100_time :  68.45690679550171\n",
            "step :  13500 iters_100_time :  68.45381236076355\n",
            "step :  13600 iters_100_time :  68.42931151390076\n",
            "step :  13700 iters_100_time :  68.37457299232483\n",
            "[441/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 54.30 Time: 303.71s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  67.60433721542358\n",
            "step :  13900 iters_100_time :  68.42448902130127\n",
            "step :  14000 iters_100_time :  68.48408675193787\n",
            "step :  14100 iters_100_time :  68.37413144111633\n",
            "[442/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 78.59 Time: 303.25s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  38.8952374458313\n",
            "step :  14300 iters_100_time :  68.37211513519287\n",
            "step :  14400 iters_100_time :  68.46658325195312\n",
            "step :  14500 iters_100_time :  68.52890229225159\n",
            "[443/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 68.50 Time: 303.52s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  10.284157514572144\n",
            "step :  14700 iters_100_time :  68.62671494483948\n",
            "step :  14800 iters_100_time :  68.62350940704346\n",
            "step :  14900 iters_100_time :  68.55194878578186\n",
            "step :  15000 iters_100_time :  68.4175443649292\n",
            "[444/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 54.54 Time: 303.98s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  49.81850814819336\n",
            "step :  15200 iters_100_time :  68.34040093421936\n",
            "step :  15300 iters_100_time :  68.40316796302795\n",
            "step :  15400 iters_100_time :  68.40496850013733\n",
            "[445/600][442]\n",
            "                    Loss_D: 0.53 Loss_G: 52.87 Time: 303.11s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  21.155884981155396\n",
            "step :  15600 iters_100_time :  68.33943581581116\n",
            "step :  15700 iters_100_time :  68.36859178543091\n",
            "step :  15800 iters_100_time :  68.35421228408813\n",
            "step :  15900 iters_100_time :  68.38931083679199\n",
            "[446/600][442]\n",
            "                    Loss_D: 0.01 Loss_G: 71.21 Time: 303.10s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  60.78163027763367\n",
            "step :  16100 iters_100_time :  68.32310914993286\n",
            "step :  16200 iters_100_time :  68.40736675262451\n",
            "step :  16300 iters_100_time :  68.39092874526978\n",
            "[447/600][442]\n",
            "                    Loss_D: 0.04 Loss_G: 50.06 Time: 303.10s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  32.12210750579834\n",
            "step :  16500 iters_100_time :  68.43595099449158\n",
            "step :  16600 iters_100_time :  68.35431265830994\n",
            "step :  16700 iters_100_time :  68.34285187721252\n",
            "[448/600][442]\n",
            "                    Loss_D: 0.29 Loss_G: 64.85 Time: 303.23s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  3.400951862335205\n",
            "step :  16900 iters_100_time :  68.3066041469574\n",
            "step :  17000 iters_100_time :  68.37019968032837\n",
            "step :  17100 iters_100_time :  68.32058310508728\n",
            "step :  17200 iters_100_time :  68.48592877388\n",
            "[449/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 64.59 Time: 303.17s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  43.05125832557678\n",
            "step :  17400 iters_100_time :  68.31710624694824\n",
            "step :  17500 iters_100_time :  68.3375985622406\n",
            "step :  17600 iters_100_time :  68.33288788795471\n",
            "[450/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 67.79 Time: 302.99s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  14.423999547958374\n",
            "step :  17800 iters_100_time :  68.28626608848572\n",
            "step :  17900 iters_100_time :  68.33953809738159\n",
            "step :  18000 iters_100_time :  68.38788533210754\n",
            "step :  18100 iters_100_time :  68.39311075210571\n",
            "[451/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 54.50 Time: 303.29s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  53.77484488487244\n",
            "step :  18300 iters_100_time :  68.35457372665405\n",
            "step :  18400 iters_100_time :  68.4586730003357\n",
            "step :  18500 iters_100_time :  68.45352959632874\n",
            "[452/600][442]\n",
            "                    Loss_D: 1.07 Loss_G: 40.77 Time: 303.07s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  25.23958110809326\n",
            "step :  18700 iters_100_time :  68.38975024223328\n",
            "step :  18800 iters_100_time :  68.43741512298584\n",
            "step :  18900 iters_100_time :  68.51626324653625\n",
            "step :  19000 iters_100_time :  68.48600006103516\n",
            "[453/600][442]\n",
            "                    Loss_D: 0.21 Loss_G: 54.29 Time: 303.49s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  65.0084433555603\n",
            "step :  19200 iters_100_time :  68.45664262771606\n",
            "step :  19300 iters_100_time :  68.44383502006531\n",
            "step :  19400 iters_100_time :  68.47126936912537\n",
            "[454/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 54.80 Time: 303.56s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  36.2858407497406\n",
            "step :  19600 iters_100_time :  68.5609803199768\n",
            "step :  19700 iters_100_time :  68.5105721950531\n",
            "step :  19800 iters_100_time :  68.53310823440552\n",
            "[455/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 59.88 Time: 303.85s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  7.541943073272705\n",
            "step :  20000 iters_100_time :  68.57215642929077\n",
            "step :  20100 iters_100_time :  68.53931021690369\n",
            "step :  20200 iters_100_time :  68.52522587776184\n",
            "step :  20300 iters_100_time :  68.49934673309326\n",
            "[456/600][442]\n",
            "                    Loss_D: 0.16 Loss_G: 50.52 Time: 303.91s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  47.42744159698486\n",
            "step :  20500 iters_100_time :  68.53254961967468\n",
            "step :  20600 iters_100_time :  68.54941821098328\n",
            "step :  20700 iters_100_time :  68.68853425979614\n",
            "[457/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 59.36 Time: 304.24s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  18.504915952682495\n",
            "step :  20900 iters_100_time :  68.57479238510132\n",
            "step :  21000 iters_100_time :  68.58262753486633\n",
            "step :  21100 iters_100_time :  68.44461965560913\n",
            "step :  21200 iters_100_time :  68.49942374229431\n",
            "[458/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 55.60 Time: 303.87s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  58.33308434486389\n",
            "step :  21400 iters_100_time :  68.59566736221313\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JqjTMflgFjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}