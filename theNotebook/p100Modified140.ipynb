{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p100Modified140.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mVHKOFJKObV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "6815748f-bdc8-4bd0-8355-907a2f3853ca"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 27 20:11:27 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X39EBfvPKZkL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "!rm -r sample_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OefxF14-aYaX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#clone repo AttnGAN\n",
        "os.chdir('/content/')\n",
        "!rm -r AttnGAN\n",
        "!git clone https://github.com/taoxugit/AttnGAN.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MAWIQ3SauxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download captionts filenames and classes info\n",
        "os.chdir('/content/AttnGAN/data/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1O_LtUP9sch09QH3s_EBAgLEctBQ5JBSJ' -O birds.zip\n",
        "!unzip -q birds.zip\n",
        "!rm birds.zip\n",
        "!rm -r __MACOSX/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCWGDFUBa3PI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "5de32237-76e9-44eb-c0ab-998d41e72b9e"
      },
      "source": [
        "# Download Cub Datatset\n",
        "os.chdir('/content/AttnGAN/data/birds/')\n",
        "!wget http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
        "!tar zxf  CUB_200_2011.tgz\n",
        "!rm CUB_200_2011.tgz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-27 20:15:58--  http://www.vision.caltech.edu/visipedia-data/CUB-200-2011/CUB_200_2011.tgz\n",
            "Resolving www.vision.caltech.edu (www.vision.caltech.edu)... 34.208.54.77\n",
            "Connecting to www.vision.caltech.edu (www.vision.caltech.edu)|34.208.54.77|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1150585339 (1.1G) [application/x-tar]\n",
            "Saving to: ‘CUB_200_2011.tgz’\n",
            "\n",
            "CUB_200_2011.tgz    100%[===================>]   1.07G  6.20MB/s    in 3m 11s  \n",
            "\n",
            "2020-06-27 20:19:09 (5.76 MB/s) - ‘CUB_200_2011.tgz’ saved [1150585339/1150585339]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ66YieGbBgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dwonload files text encoder and image encoder\n",
        "os.chdir('/content/AttnGAN/DAMSMencoders/')\n",
        "!rm -r bird/\n",
        "os.mkdir('bird')\n",
        "os.chdir('/content/')\n",
        "!git clone https://github.com/ammarnasr/CUB-Attn-GAN.git\n",
        "\n",
        "# #Move Models text and image encoder to their /content/\n",
        "!mv  /content/CUB-Attn-GAN/theModel/text_encoder599.pth  /content/AttnGAN/DAMSMencoders/bird/\n",
        "!mv /content/CUB-Attn-GAN/theModel/image_encoder599.pth /content/AttnGAN/DAMSMencoders/bird/\n",
        "\n",
        "!rm -r CUB-Attn-GAN "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7JAGGYmb4n1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download Pillow Font\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Wr3lQajG7m6Bi3rYFTJb6mwE_d8su111' -O Pillow.rar\n",
        "!unrar x  Pillow.rar\n",
        "!rm Pillow.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVh_H_ROb-C3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checkpoint from drive, edit in bird_attnGAN2.ymal also\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netG_epoch_140.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD0.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD1.pth' '/content/AttnGAN/models/'\n",
        "!cp '/content/drive/My Drive/ModifiedcubModelGAN/netD2.pth' '/content/AttnGAN/models/'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbwcsIpCb_Pb",
        "colab_type": "text"
      },
      "source": [
        "# ============================================="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmJ7SXu2cAmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Move code files to their Locations\n",
        "os.chdir('/content')\n",
        "!rm -r Modified_CUB_Attn_GAN/\n",
        "!git clone https://github.com/ammarnasr/Modified_CUB_Attn_GAN.git\n",
        "\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/config.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/utils.py                      /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/datasets.py                  /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/GlobalAttention.py          /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/model.py                   /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/losses.py                 /content/AttnGAN/code/miscc/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/trainer.py               /content/AttnGAN/code/\n",
        "!mv /content/Modified_CUB_Attn_GAN/theCode/bird_attn2.yml          /content/AttnGAN/code/cfg/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycr6eGWNca8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e75d06c8-5e2e-4a01-e036-5338d187ffc1"
      },
      "source": [
        "#run Code\n",
        "os.chdir('/content/AttnGAN/code/')\n",
        "!python main.py --cfg cfg/bird_attn2.yml --gpu 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using config:\n",
            "{'B_VALIDATION': False,\n",
            " 'CONFIG_NAME': 'attn2',\n",
            " 'CUDA': True,\n",
            " 'DATASET_NAME': 'birds',\n",
            " 'DATA_DIR': '../data/birds',\n",
            " 'GAN': {'B_ATTENTION': True,\n",
            "         'B_DCGAN': False,\n",
            "         'CONDITION_DIM': 100,\n",
            "         'DF_DIM': 64,\n",
            "         'GF_DIM': 32,\n",
            "         'R_NUM': 2,\n",
            "         'Z_DIM': 100},\n",
            " 'GPU_ID': 0,\n",
            " 'RNN_TYPE': 'LSTM',\n",
            " 'TEXT': {'CAPTIONS_PER_IMAGE': 10, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 18},\n",
            " 'TRAIN': {'BATCH_SIZE': 20,\n",
            "           'B_NET_D': True,\n",
            "           'DISCRIMINATOR_LR': 0.0002,\n",
            "           'ENCODER_LR': 0.0002,\n",
            "           'FLAG': True,\n",
            "           'GENERATOR_LR': 0.0002,\n",
            "           'MAX_EPOCH': 600,\n",
            "           'NET_E': '../DAMSMencoders/bird/text_encoder599.pth',\n",
            "           'NET_G': '../models/netG_epoch_140.pth',\n",
            "           'RNN_GRAD_CLIP': 0.25,\n",
            "           'SMOOTH': {'GAMMA1': 4.0,\n",
            "                      'GAMMA2': 5.0,\n",
            "                      'GAMMA3': 10.0,\n",
            "                      'LAMBDA': 5.0},\n",
            "           'SNAPSHOT_INTERVAL': 10},\n",
            " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
            " 'WORKERS': 4}\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py:211: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n",
            "Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\n",
            "Load filenames from: ../data/birds/train/filenames.pickle (8855)\n",
            "Load filenames from: ../data/birds/test/filenames.pickle (2933)\n",
            "Load from:  ../data/birds/captions.pickle\n",
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /root/.cache/torch/checkpoints/inception_v3_google-1a9a5a14.pth\n",
            "100% 104M/104M [00:00<00:00, 116MB/s] \n",
            "Load pretrained model from  https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\n",
            "Load image encoder from: ../DAMSMencoders/bird/image_encoder599.pth\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "Load text encoder from: ../DAMSMencoders/bird/text_encoder599.pth\n",
            "/content/AttnGAN/code/miscc/utils.py:404: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "/content/AttnGAN/code/miscc/utils.py:399: UserWarning: nn.init.orthogonal is now deprecated in favor of nn.init.orthogonal_.\n",
            "  nn.init.orthogonal(m.weight.data, 1.0)\n",
            "# of netsD 3\n",
            "Load G from:  ../models/netG_epoch_140.pth\n",
            "Load D from:  ../models/netD0.pth\n",
            "Load D from:  ../models/netD1.pth\n",
            "Load D from:  ../models/netD2.pth\n",
            "num_batches :  442\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/content/AttnGAN/code/GlobalAttention.py:116: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = self.sm(attn)  # Eq. (2)\n",
            "/content/AttnGAN/code/GlobalAttention.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  sent_att                = nn.Softmax()(sentence_vs)  # batch x idf x ih x iw\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/content/AttnGAN/code/GlobalAttention.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)  # Eq. (8)\n",
            "/content/AttnGAN/code/GlobalAttention.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  attn = nn.Softmax()(attn)\n",
            "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha)\n",
            "step :  100 iters_100_time :  75.3773546218872\n",
            "step :  200 iters_100_time :  71.35676145553589\n",
            "step :  300 iters_100_time :  71.23731994628906\n",
            "step :  400 iters_100_time :  71.26053643226624\n",
            "[141/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 57.80 Time: 319.19s\n",
            "num_batches :  442\n",
            "step :  500 iters_100_time :  42.13280773162842\n",
            "step :  600 iters_100_time :  71.19192600250244\n",
            "step :  700 iters_100_time :  71.15737438201904\n",
            "step :  800 iters_100_time :  71.14669919013977\n",
            "[142/600][442]\n",
            "                    Loss_D: 1.13 Loss_G: 67.10 Time: 315.64s\n",
            "num_batches :  442\n",
            "step :  900 iters_100_time :  12.353253841400146\n",
            "step :  1000 iters_100_time :  71.21710062026978\n",
            "step :  1100 iters_100_time :  71.15586161613464\n",
            "step :  1200 iters_100_time :  71.16703915596008\n",
            "step :  1300 iters_100_time :  71.18443274497986\n",
            "[143/600][442]\n",
            "                    Loss_D: 1.44 Loss_G: 30.59 Time: 315.85s\n",
            "num_batches :  442\n",
            "step :  1400 iters_100_time :  53.41572427749634\n",
            "step :  1500 iters_100_time :  71.22643780708313\n",
            "step :  1600 iters_100_time :  71.2356071472168\n",
            "step :  1700 iters_100_time :  71.1666374206543\n",
            "[144/600][442]\n",
            "                    Loss_D: 0.83 Loss_G: 56.82 Time: 315.80s\n",
            "num_batches :  442\n",
            "step :  1800 iters_100_time :  23.52195405960083\n",
            "step :  1900 iters_100_time :  71.30278301239014\n",
            "step :  2000 iters_100_time :  71.29013776779175\n",
            "step :  2100 iters_100_time :  71.19599771499634\n",
            "step :  2200 iters_100_time :  71.1796362400055\n",
            "[145/600][442]\n",
            "                    Loss_D: 2.07 Loss_G: 28.46 Time: 315.91s\n",
            "num_batches :  442\n",
            "step :  2300 iters_100_time :  64.94104075431824\n",
            "step :  2400 iters_100_time :  71.12113904953003\n",
            "step :  2500 iters_100_time :  71.12730407714844\n",
            "step :  2600 iters_100_time :  71.27058172225952\n",
            "[146/600][442]\n",
            "                    Loss_D: 2.01 Loss_G: 59.49 Time: 315.78s\n",
            "num_batches :  442\n",
            "step :  2700 iters_100_time :  35.025731801986694\n",
            "step :  2800 iters_100_time :  71.17768335342407\n",
            "step :  2900 iters_100_time :  71.20655822753906\n",
            "step :  3000 iters_100_time :  71.17053461074829\n",
            "[147/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 48.79 Time: 315.77s\n",
            "num_batches :  442\n",
            "step :  3100 iters_100_time :  5.176396131515503\n",
            "step :  3200 iters_100_time :  71.08080196380615\n",
            "step :  3300 iters_100_time :  71.08854055404663\n",
            "step :  3400 iters_100_time :  71.1584300994873\n",
            "step :  3500 iters_100_time :  71.15619158744812\n",
            "[148/600][442]\n",
            "                    Loss_D: 2.16 Loss_G: 67.43 Time: 315.57s\n",
            "num_batches :  442\n",
            "step :  3600 iters_100_time :  46.43047022819519\n",
            "step :  3700 iters_100_time :  71.10564541816711\n",
            "step :  3800 iters_100_time :  71.06822657585144\n",
            "step :  3900 iters_100_time :  71.15825247764587\n",
            "[149/600][442]\n",
            "                    Loss_D: 0.94 Loss_G: 35.91 Time: 315.57s\n",
            "num_batches :  442\n",
            "step :  4000 iters_100_time :  16.543966054916382\n",
            "step :  4100 iters_100_time :  71.09896636009216\n",
            "step :  4200 iters_100_time :  71.17387127876282\n",
            "step :  4300 iters_100_time :  71.23059439659119\n",
            "step :  4400 iters_100_time :  71.28638315200806\n",
            "[150/600][442]\n",
            "                    Loss_D: 1.08 Loss_G: 57.09 Time: 315.87s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  4500 iters_100_time :  58.11201333999634\n",
            "step :  4600 iters_100_time :  71.21091723442078\n",
            "step :  4700 iters_100_time :  71.2031500339508\n",
            "step :  4800 iters_100_time :  71.18300890922546\n",
            "[151/600][442]\n",
            "                    Loss_D: 0.46 Loss_G: 50.14 Time: 316.23s\n",
            "num_batches :  442\n",
            "step :  4900 iters_100_time :  27.879766941070557\n",
            "step :  5000 iters_100_time :  71.05538511276245\n",
            "step :  5100 iters_100_time :  70.88349723815918\n",
            "step :  5200 iters_100_time :  71.02044320106506\n",
            "step :  5300 iters_100_time :  71.02499461174011\n",
            "[152/600][442]\n",
            "                    Loss_D: 0.67 Loss_G: 43.00 Time: 315.04s\n",
            "num_batches :  442\n",
            "step :  5400 iters_100_time :  69.04919266700745\n",
            "step :  5500 iters_100_time :  71.13824653625488\n",
            "step :  5600 iters_100_time :  71.11690354347229\n",
            "step :  5700 iters_100_time :  71.18482112884521\n",
            "[153/600][442]\n",
            "                    Loss_D: 6.19 Loss_G: 20.14 Time: 315.50s\n",
            "num_batches :  442\n",
            "step :  5800 iters_100_time :  39.313523054122925\n",
            "step :  5900 iters_100_time :  70.91610479354858\n",
            "step :  6000 iters_100_time :  71.05078125\n",
            "step :  6100 iters_100_time :  71.12444400787354\n",
            "[154/600][442]\n",
            "                    Loss_D: 0.30 Loss_G: 43.54 Time: 315.31s\n",
            "num_batches :  442\n",
            "step :  6200 iters_100_time :  9.42705750465393\n",
            "step :  6300 iters_100_time :  71.07380414009094\n",
            "step :  6400 iters_100_time :  71.02769064903259\n",
            "step :  6500 iters_100_time :  70.92376613616943\n",
            "step :  6600 iters_100_time :  71.05472707748413\n",
            "[155/600][442]\n",
            "                    Loss_D: 0.51 Loss_G: 63.78 Time: 315.10s\n",
            "num_batches :  442\n",
            "step :  6700 iters_100_time :  50.60391807556152\n",
            "step :  6800 iters_100_time :  71.02993392944336\n",
            "step :  6900 iters_100_time :  71.05042576789856\n",
            "step :  7000 iters_100_time :  71.10020804405212\n",
            "[156/600][442]\n",
            "                    Loss_D: 0.41 Loss_G: 51.98 Time: 315.32s\n",
            "num_batches :  442\n",
            "step :  7100 iters_100_time :  20.757355451583862\n",
            "step :  7200 iters_100_time :  71.01202964782715\n",
            "step :  7300 iters_100_time :  71.04732990264893\n",
            "step :  7400 iters_100_time :  71.16995334625244\n",
            "step :  7500 iters_100_time :  71.12881278991699\n",
            "[157/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 49.08 Time: 315.37s\n",
            "num_batches :  442\n",
            "step :  7600 iters_100_time :  62.07465696334839\n",
            "step :  7700 iters_100_time :  71.14775967597961\n",
            "step :  7800 iters_100_time :  71.05079126358032\n",
            "step :  7900 iters_100_time :  71.05403900146484\n",
            "[158/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 54.97 Time: 315.35s\n",
            "num_batches :  442\n",
            "step :  8000 iters_100_time :  32.15937948226929\n",
            "step :  8100 iters_100_time :  71.10337781906128\n",
            "step :  8200 iters_100_time :  71.0258960723877\n",
            "step :  8300 iters_100_time :  71.08004403114319\n",
            "[159/600][442]\n",
            "                    Loss_D: 0.69 Loss_G: 57.62 Time: 315.24s\n",
            "num_batches :  442\n",
            "step :  8400 iters_100_time :  2.2409353256225586\n",
            "step :  8500 iters_100_time :  71.00581288337708\n",
            "step :  8600 iters_100_time :  71.09743547439575\n",
            "step :  8700 iters_100_time :  71.0595498085022\n",
            "step :  8800 iters_100_time :  71.06202173233032\n",
            "[160/600][442]\n",
            "                    Loss_D: 0.49 Loss_G: 52.62 Time: 315.22s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  8900 iters_100_time :  43.72253465652466\n",
            "step :  9000 iters_100_time :  71.13569664955139\n",
            "step :  9100 iters_100_time :  71.10753679275513\n",
            "step :  9200 iters_100_time :  71.145259141922\n",
            "[161/600][442]\n",
            "                    Loss_D: 0.37 Loss_G: 52.65 Time: 315.77s\n",
            "num_batches :  442\n",
            "step :  9300 iters_100_time :  13.593303680419922\n",
            "step :  9400 iters_100_time :  71.08828544616699\n",
            "step :  9500 iters_100_time :  71.1054756641388\n",
            "step :  9600 iters_100_time :  71.0440776348114\n",
            "step :  9700 iters_100_time :  71.11212134361267\n",
            "[162/600][442]\n",
            "                    Loss_D: 0.14 Loss_G: 72.61 Time: 315.39s\n",
            "num_batches :  442\n",
            "step :  9800 iters_100_time :  55.002273082733154\n",
            "step :  9900 iters_100_time :  71.25153613090515\n",
            "step :  10000 iters_100_time :  71.2042293548584\n",
            "step :  10100 iters_100_time :  71.17086052894592\n",
            "[163/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 54.08 Time: 315.79s\n",
            "num_batches :  442\n",
            "step :  10200 iters_100_time :  24.904247045516968\n",
            "step :  10300 iters_100_time :  71.09701871871948\n",
            "step :  10400 iters_100_time :  71.00456428527832\n",
            "step :  10500 iters_100_time :  71.01086282730103\n",
            "step :  10600 iters_100_time :  71.08402490615845\n",
            "[164/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 44.34 Time: 315.09s\n",
            "num_batches :  442\n",
            "step :  10700 iters_100_time :  66.16115140914917\n",
            "step :  10800 iters_100_time :  71.02658009529114\n",
            "step :  10900 iters_100_time :  71.04281711578369\n",
            "step :  11000 iters_100_time :  70.98609495162964\n",
            "[165/600][442]\n",
            "                    Loss_D: 0.48 Loss_G: 57.45 Time: 315.06s\n",
            "num_batches :  442\n",
            "step :  11100 iters_100_time :  36.35605549812317\n",
            "step :  11200 iters_100_time :  71.03198647499084\n",
            "step :  11300 iters_100_time :  71.12336349487305\n",
            "step :  11400 iters_100_time :  71.07898712158203\n",
            "[166/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 52.48 Time: 315.29s\n",
            "num_batches :  442\n",
            "step :  11500 iters_100_time :  6.614105224609375\n",
            "step :  11600 iters_100_time :  71.23500156402588\n",
            "step :  11700 iters_100_time :  71.16757559776306\n",
            "step :  11800 iters_100_time :  71.09188866615295\n",
            "step :  11900 iters_100_time :  71.1925208568573\n",
            "[167/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 48.42 Time: 315.77s\n",
            "num_batches :  442\n",
            "step :  12000 iters_100_time :  47.8162157535553\n",
            "step :  12100 iters_100_time :  71.0033016204834\n",
            "step :  12200 iters_100_time :  71.02981400489807\n",
            "step :  12300 iters_100_time :  71.06629705429077\n",
            "[168/600][442]\n",
            "                    Loss_D: 0.43 Loss_G: 55.21 Time: 315.19s\n",
            "num_batches :  442\n",
            "step :  12400 iters_100_time :  17.795039653778076\n",
            "step :  12500 iters_100_time :  71.11365532875061\n",
            "step :  12600 iters_100_time :  71.13551950454712\n",
            "step :  12700 iters_100_time :  71.09822583198547\n",
            "step :  12800 iters_100_time :  71.10197138786316\n",
            "[169/600][442]\n",
            "                    Loss_D: 0.93 Loss_G: 45.61 Time: 315.34s\n",
            "num_batches :  442\n",
            "step :  12900 iters_100_time :  59.0356822013855\n",
            "step :  13000 iters_100_time :  71.06285762786865\n",
            "step :  13100 iters_100_time :  71.07618761062622\n",
            "step :  13200 iters_100_time :  70.97627520561218\n",
            "[170/600][442]\n",
            "                    Loss_D: 0.59 Loss_G: 50.37 Time: 315.11s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  13300 iters_100_time :  29.454657077789307\n",
            "step :  13400 iters_100_time :  71.03321194648743\n",
            "step :  13500 iters_100_time :  71.08610105514526\n",
            "step :  13600 iters_100_time :  71.21951603889465\n",
            "step :  13700 iters_100_time :  71.36119031906128\n",
            "[171/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 36.07 Time: 316.04s\n",
            "num_batches :  442\n",
            "step :  13800 iters_100_time :  70.82090997695923\n",
            "step :  13900 iters_100_time :  71.32866382598877\n",
            "step :  14000 iters_100_time :  71.30741238594055\n",
            "step :  14100 iters_100_time :  71.51117396354675\n",
            "[172/600][442]\n",
            "                    Loss_D: 1.33 Loss_G: 66.74 Time: 316.73s\n",
            "num_batches :  442\n",
            "step :  14200 iters_100_time :  41.095600605010986\n",
            "step :  14300 iters_100_time :  71.45802545547485\n",
            "step :  14400 iters_100_time :  71.27874112129211\n",
            "step :  14500 iters_100_time :  71.09789705276489\n",
            "[173/600][442]\n",
            "                    Loss_D: 1.29 Loss_G: 55.16 Time: 316.52s\n",
            "num_batches :  442\n",
            "step :  14600 iters_100_time :  10.885046005249023\n",
            "step :  14700 iters_100_time :  71.09186935424805\n",
            "step :  14800 iters_100_time :  71.20427179336548\n",
            "step :  14900 iters_100_time :  70.98884534835815\n",
            "step :  15000 iters_100_time :  70.99327540397644\n",
            "[174/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 45.96 Time: 315.34s\n",
            "num_batches :  442\n",
            "step :  15100 iters_100_time :  51.86853241920471\n",
            "step :  15200 iters_100_time :  71.03522419929504\n",
            "step :  15300 iters_100_time :  71.129070520401\n",
            "step :  15400 iters_100_time :  71.21243119239807\n",
            "[175/600][442]\n",
            "                    Loss_D: 0.41 Loss_G: 40.50 Time: 315.44s\n",
            "num_batches :  442\n",
            "step :  15500 iters_100_time :  22.15841579437256\n",
            "step :  15600 iters_100_time :  71.21091151237488\n",
            "step :  15700 iters_100_time :  71.23413872718811\n",
            "step :  15800 iters_100_time :  71.28039050102234\n",
            "step :  15900 iters_100_time :  71.24599075317383\n",
            "[176/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 59.48 Time: 315.98s\n",
            "num_batches :  442\n",
            "step :  16000 iters_100_time :  63.46032977104187\n",
            "step :  16100 iters_100_time :  71.20560216903687\n",
            "step :  16200 iters_100_time :  71.38103652000427\n",
            "step :  16300 iters_100_time :  71.26496744155884\n",
            "[177/600][442]\n",
            "                    Loss_D: 0.47 Loss_G: 37.71 Time: 316.10s\n",
            "num_batches :  442\n",
            "step :  16400 iters_100_time :  33.55474829673767\n",
            "step :  16500 iters_100_time :  71.29711580276489\n",
            "step :  16600 iters_100_time :  71.23370838165283\n",
            "step :  16700 iters_100_time :  71.12889766693115\n",
            "[178/600][442]\n",
            "                    Loss_D: 1.66 Loss_G: 66.02 Time: 315.92s\n",
            "num_batches :  442\n",
            "step :  16800 iters_100_time :  3.6559290885925293\n",
            "step :  16900 iters_100_time :  71.20524024963379\n",
            "step :  17000 iters_100_time :  71.29520988464355\n",
            "step :  17100 iters_100_time :  71.09450244903564\n",
            "step :  17200 iters_100_time :  71.09118413925171\n",
            "[179/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 49.24 Time: 315.70s\n",
            "num_batches :  442\n",
            "step :  17300 iters_100_time :  44.90863227844238\n",
            "step :  17400 iters_100_time :  71.20702767372131\n",
            "step :  17500 iters_100_time :  71.07394623756409\n",
            "step :  17600 iters_100_time :  71.12950468063354\n",
            "[180/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 44.95 Time: 315.51s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  17700 iters_100_time :  15.32487440109253\n",
            "step :  17800 iters_100_time :  71.1167562007904\n",
            "step :  17900 iters_100_time :  71.0706295967102\n",
            "step :  18000 iters_100_time :  71.17913579940796\n",
            "step :  18100 iters_100_time :  71.12102699279785\n",
            "[181/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 49.73 Time: 315.83s\n",
            "num_batches :  442\n",
            "step :  18200 iters_100_time :  56.1736273765564\n",
            "step :  18300 iters_100_time :  71.1083996295929\n",
            "step :  18400 iters_100_time :  71.04307818412781\n",
            "step :  18500 iters_100_time :  71.09102821350098\n",
            "[182/600][442]\n",
            "                    Loss_D: 0.34 Loss_G: 39.59 Time: 315.17s\n",
            "num_batches :  442\n",
            "step :  18600 iters_100_time :  26.39247727394104\n",
            "step :  18700 iters_100_time :  71.13456749916077\n",
            "step :  18800 iters_100_time :  71.08927011489868\n",
            "step :  18900 iters_100_time :  71.10481190681458\n",
            "step :  19000 iters_100_time :  71.1102237701416\n",
            "[183/600][442]\n",
            "                    Loss_D: 0.07 Loss_G: 40.84 Time: 315.42s\n",
            "num_batches :  442\n",
            "step :  19100 iters_100_time :  67.66197752952576\n",
            "step :  19200 iters_100_time :  71.11520671844482\n",
            "step :  19300 iters_100_time :  71.06165194511414\n",
            "step :  19400 iters_100_time :  71.1283347606659\n",
            "[184/600][442]\n",
            "                    Loss_D: 0.37 Loss_G: 52.52 Time: 315.49s\n",
            "num_batches :  442\n",
            "step :  19500 iters_100_time :  37.8343608379364\n",
            "step :  19600 iters_100_time :  71.15590405464172\n",
            "step :  19700 iters_100_time :  71.09571242332458\n",
            "step :  19800 iters_100_time :  71.13633394241333\n",
            "[185/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 52.85 Time: 315.47s\n",
            "num_batches :  442\n",
            "step :  19900 iters_100_time :  7.857541799545288\n",
            "step :  20000 iters_100_time :  71.03375387191772\n",
            "step :  20100 iters_100_time :  71.1064043045044\n",
            "step :  20200 iters_100_time :  71.12701368331909\n",
            "step :  20300 iters_100_time :  71.04289722442627\n",
            "[186/600][442]\n",
            "                    Loss_D: 0.51 Loss_G: 50.70 Time: 315.22s\n",
            "num_batches :  442\n",
            "step :  20400 iters_100_time :  48.9674551486969\n",
            "step :  20500 iters_100_time :  71.12848711013794\n",
            "step :  20600 iters_100_time :  71.09056901931763\n",
            "step :  20700 iters_100_time :  71.12401700019836\n",
            "[187/600][442]\n",
            "                    Loss_D: 0.73 Loss_G: 52.47 Time: 315.30s\n",
            "num_batches :  442\n",
            "step :  20800 iters_100_time :  19.23626947402954\n",
            "step :  20900 iters_100_time :  71.05278396606445\n",
            "step :  21000 iters_100_time :  71.01857805252075\n",
            "step :  21100 iters_100_time :  71.13627243041992\n",
            "step :  21200 iters_100_time :  70.95149540901184\n",
            "[188/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 71.55 Time: 315.02s\n",
            "num_batches :  442\n",
            "step :  21300 iters_100_time :  60.38073945045471\n",
            "step :  21400 iters_100_time :  71.07516741752625\n",
            "step :  21500 iters_100_time :  71.15792560577393\n",
            "step :  21600 iters_100_time :  71.10735821723938\n",
            "[189/600][442]\n",
            "                    Loss_D: 1.17 Loss_G: 51.78 Time: 315.23s\n",
            "num_batches :  442\n",
            "step :  21700 iters_100_time :  30.765461683273315\n",
            "step :  21800 iters_100_time :  70.98218894004822\n",
            "step :  21900 iters_100_time :  71.1124620437622\n",
            "step :  22000 iters_100_time :  71.14228081703186\n",
            "step :  22100 iters_100_time :  71.00653386116028\n",
            "[190/600][442]\n",
            "                    Loss_D: 1.07 Loss_G: 64.63 Time: 315.37s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  22200 iters_100_time :  72.36521410942078\n",
            "step :  22300 iters_100_time :  70.99067544937134\n",
            "step :  22400 iters_100_time :  70.95188236236572\n",
            "step :  22500 iters_100_time :  70.88820457458496\n",
            "[191/600][442]\n",
            "                    Loss_D: 0.19 Loss_G: 56.37 Time: 315.34s\n",
            "num_batches :  442\n",
            "step :  22600 iters_100_time :  42.005370140075684\n",
            "step :  22700 iters_100_time :  70.89044713973999\n",
            "step :  22800 iters_100_time :  71.01646113395691\n",
            "step :  22900 iters_100_time :  70.89508509635925\n",
            "[192/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 54.07 Time: 314.70s\n",
            "num_batches :  442\n",
            "step :  23000 iters_100_time :  12.151331901550293\n",
            "step :  23100 iters_100_time :  71.0824282169342\n",
            "step :  23200 iters_100_time :  70.95021557807922\n",
            "step :  23300 iters_100_time :  70.91220188140869\n",
            "step :  23400 iters_100_time :  70.82364892959595\n",
            "[193/600][442]\n",
            "                    Loss_D: 2.64 Loss_G: 70.46 Time: 314.61s\n",
            "num_batches :  442\n",
            "step :  23500 iters_100_time :  53.29826211929321\n",
            "step :  23600 iters_100_time :  70.88603734970093\n",
            "step :  23700 iters_100_time :  71.13271236419678\n",
            "step :  23800 iters_100_time :  71.0398530960083\n",
            "[194/600][442]\n",
            "                    Loss_D: 0.77 Loss_G: 51.71 Time: 314.83s\n",
            "num_batches :  442\n",
            "step :  23900 iters_100_time :  23.495633840560913\n",
            "step :  24000 iters_100_time :  70.9591965675354\n",
            "step :  24100 iters_100_time :  70.88064241409302\n",
            "step :  24200 iters_100_time :  70.9509174823761\n",
            "step :  24300 iters_100_time :  71.05387425422668\n",
            "[195/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 67.43 Time: 314.75s\n",
            "num_batches :  442\n",
            "step :  24400 iters_100_time :  64.70226120948792\n",
            "step :  24500 iters_100_time :  70.87086915969849\n",
            "step :  24600 iters_100_time :  70.88141369819641\n",
            "step :  24700 iters_100_time :  70.86895298957825\n",
            "[196/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 56.53 Time: 314.47s\n",
            "num_batches :  442\n",
            "step :  24800 iters_100_time :  34.90328788757324\n",
            "step :  24900 iters_100_time :  70.86399221420288\n",
            "step :  25000 iters_100_time :  70.83862447738647\n",
            "step :  25000 iters_5000_time :  176.6060609817505\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  7.426437616348267\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  28.039674282073975\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "CURRENT WORKING DIRCTORY :  /content/AttnGAN/code\n",
            "keyTime |||||||||||||||||||||||||||||||\n",
            "build_super_images_time :  227.59831285476685\n",
            "KeyTime |||||||||||||||||||||||||||||||\n",
            "step :  25100 iters_100_time :  355.6784403324127\n",
            "[197/600][442]\n",
            "                    Loss_D: 0.31 Loss_G: 41.83 Time: 599.20s\n",
            "num_batches :  442\n",
            "step :  25200 iters_100_time :  5.02270770072937\n",
            "step :  25300 iters_100_time :  70.95575666427612\n",
            "step :  25400 iters_100_time :  70.99767303466797\n",
            "step :  25500 iters_100_time :  71.04542756080627\n",
            "step :  25600 iters_100_time :  71.00389552116394\n",
            "[198/600][442]\n",
            "                    Loss_D: 0.39 Loss_G: 43.64 Time: 314.92s\n",
            "num_batches :  442\n",
            "step :  25700 iters_100_time :  46.23820662498474\n",
            "step :  25800 iters_100_time :  70.91868495941162\n",
            "step :  25900 iters_100_time :  70.89961886405945\n",
            "step :  26000 iters_100_time :  70.9624490737915\n",
            "[199/600][442]\n",
            "                    Loss_D: 0.35 Loss_G: 43.92 Time: 314.70s\n",
            "num_batches :  442\n",
            "step :  26100 iters_100_time :  16.429816007614136\n",
            "step :  26200 iters_100_time :  70.92433428764343\n",
            "step :  26300 iters_100_time :  70.90670132637024\n",
            "step :  26400 iters_100_time :  70.97930955886841\n",
            "step :  26500 iters_100_time :  70.86022138595581\n",
            "[200/600][442]\n",
            "                    Loss_D: 1.37 Loss_G: 43.52 Time: 314.67s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  26600 iters_100_time :  57.81631064414978\n",
            "step :  26700 iters_100_time :  70.98826766014099\n",
            "step :  26800 iters_100_time :  71.03714442253113\n",
            "step :  26900 iters_100_time :  71.1294298171997\n",
            "[201/600][442]\n",
            "                    Loss_D: 0.02 Loss_G: 58.80 Time: 315.45s\n",
            "num_batches :  442\n",
            "step :  27000 iters_100_time :  27.817651748657227\n",
            "step :  27100 iters_100_time :  71.08071708679199\n",
            "step :  27200 iters_100_time :  71.07884001731873\n",
            "step :  27300 iters_100_time :  71.01835632324219\n",
            "step :  27400 iters_100_time :  71.00465226173401\n",
            "[202/600][442]\n",
            "                    Loss_D: 1.57 Loss_G: 58.28 Time: 315.25s\n",
            "num_batches :  442\n",
            "step :  27500 iters_100_time :  68.6910879611969\n",
            "step :  27600 iters_100_time :  70.98676228523254\n",
            "step :  27700 iters_100_time :  70.97471189498901\n",
            "step :  27800 iters_100_time :  70.87057900428772\n",
            "[203/600][442]\n",
            "                    Loss_D: 0.24 Loss_G: 43.83 Time: 314.49s\n",
            "num_batches :  442\n",
            "step :  27900 iters_100_time :  39.12728834152222\n",
            "step :  28000 iters_100_time :  71.04047012329102\n",
            "step :  28100 iters_100_time :  70.99721145629883\n",
            "step :  28200 iters_100_time :  71.04461312294006\n",
            "[204/600][442]\n",
            "                    Loss_D: 0.08 Loss_G: 60.14 Time: 315.20s\n",
            "num_batches :  442\n",
            "step :  28300 iters_100_time :  9.117369174957275\n",
            "step :  28400 iters_100_time :  71.04581880569458\n",
            "step :  28500 iters_100_time :  71.05983209609985\n",
            "step :  28600 iters_100_time :  71.05058264732361\n",
            "step :  28700 iters_100_time :  70.98663210868835\n",
            "[205/600][442]\n",
            "                    Loss_D: 0.52 Loss_G: 28.31 Time: 314.95s\n",
            "num_batches :  442\n",
            "step :  28800 iters_100_time :  50.50690054893494\n",
            "step :  28900 iters_100_time :  71.0376329421997\n",
            "step :  29000 iters_100_time :  70.95497441291809\n",
            "step :  29100 iters_100_time :  70.95173978805542\n",
            "[206/600][442]\n",
            "                    Loss_D: 0.31 Loss_G: 43.37 Time: 314.87s\n",
            "num_batches :  442\n",
            "step :  29200 iters_100_time :  20.718199491500854\n",
            "step :  29300 iters_100_time :  70.96798658370972\n",
            "step :  29400 iters_100_time :  70.88565492630005\n",
            "step :  29500 iters_100_time :  71.02665281295776\n",
            "step :  29600 iters_100_time :  71.07468819618225\n",
            "[207/600][442]\n",
            "                    Loss_D: 2.38 Loss_G: 46.11 Time: 314.98s\n",
            "num_batches :  442\n",
            "step :  29700 iters_100_time :  61.92693829536438\n",
            "step :  29800 iters_100_time :  70.99921798706055\n",
            "step :  29900 iters_100_time :  70.93466877937317\n",
            "step :  30000 iters_100_time :  70.9342589378357\n",
            "[208/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 56.64 Time: 314.99s\n",
            "num_batches :  442\n",
            "step :  30100 iters_100_time :  32.096352338790894\n",
            "step :  30200 iters_100_time :  71.04475450515747\n",
            "step :  30300 iters_100_time :  70.9908983707428\n",
            "step :  30400 iters_100_time :  71.02607011795044\n",
            "[209/600][442]\n",
            "                    Loss_D: 3.78 Loss_G: 35.11 Time: 315.08s\n",
            "num_batches :  442\n",
            "step :  30500 iters_100_time :  2.2785940170288086\n",
            "step :  30600 iters_100_time :  71.02502584457397\n",
            "step :  30700 iters_100_time :  70.96457386016846\n",
            "step :  30800 iters_100_time :  71.07615280151367\n",
            "step :  30900 iters_100_time :  71.2036828994751\n",
            "[210/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 72.07 Time: 315.36s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  31000 iters_100_time :  43.88591003417969\n",
            "step :  31100 iters_100_time :  71.04127931594849\n",
            "step :  31200 iters_100_time :  71.0498776435852\n",
            "step :  31300 iters_100_time :  71.07006311416626\n",
            "[211/600][442]\n",
            "                    Loss_D: 0.81 Loss_G: 67.35 Time: 315.76s\n",
            "num_batches :  442\n",
            "step :  31400 iters_100_time :  13.732545137405396\n",
            "step :  31500 iters_100_time :  71.03726577758789\n",
            "step :  31600 iters_100_time :  71.12144041061401\n",
            "step :  31700 iters_100_time :  71.21040916442871\n",
            "step :  31800 iters_100_time :  71.17897629737854\n",
            "[212/600][442]\n",
            "                    Loss_D: 2.61 Loss_G: 71.35 Time: 315.69s\n",
            "num_batches :  442\n",
            "step :  31900 iters_100_time :  54.962408781051636\n",
            "step :  32000 iters_100_time :  71.11584949493408\n",
            "step :  32100 iters_100_time :  71.19616055488586\n",
            "step :  32200 iters_100_time :  71.1179518699646\n",
            "[213/600][442]\n",
            "                    Loss_D: 0.28 Loss_G: 46.53 Time: 315.68s\n",
            "num_batches :  442\n",
            "step :  32300 iters_100_time :  24.978485822677612\n",
            "step :  32400 iters_100_time :  71.08155536651611\n",
            "step :  32500 iters_100_time :  71.05730319023132\n",
            "step :  32600 iters_100_time :  71.03368282318115\n",
            "step :  32700 iters_100_time :  71.1652295589447\n",
            "[214/600][442]\n",
            "                    Loss_D: 1.01 Loss_G: 63.90 Time: 315.38s\n",
            "num_batches :  442\n",
            "step :  32800 iters_100_time :  66.28513145446777\n",
            "step :  32900 iters_100_time :  71.05033946037292\n",
            "step :  33000 iters_100_time :  70.923330783844\n",
            "step :  33100 iters_100_time :  70.9978597164154\n",
            "[215/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 50.53 Time: 315.14s\n",
            "num_batches :  442\n",
            "step :  33200 iters_100_time :  36.31764197349548\n",
            "step :  33300 iters_100_time :  70.9751570224762\n",
            "step :  33400 iters_100_time :  71.09290051460266\n",
            "step :  33500 iters_100_time :  71.02209901809692\n",
            "[216/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 48.20 Time: 315.11s\n",
            "num_batches :  442\n",
            "step :  33600 iters_100_time :  6.597659587860107\n",
            "step :  33700 iters_100_time :  70.96350932121277\n",
            "step :  33800 iters_100_time :  71.06622314453125\n",
            "step :  33900 iters_100_time :  71.16842794418335\n",
            "step :  34000 iters_100_time :  71.17221808433533\n",
            "[217/600][442]\n",
            "                    Loss_D: 0.03 Loss_G: 50.02 Time: 315.49s\n",
            "num_batches :  442\n",
            "step :  34100 iters_100_time :  47.752113580703735\n",
            "step :  34200 iters_100_time :  71.07147526741028\n",
            "step :  34300 iters_100_time :  71.07882809638977\n",
            "step :  34400 iters_100_time :  71.05127334594727\n",
            "[218/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 55.31 Time: 315.40s\n",
            "num_batches :  442\n",
            "step :  34500 iters_100_time :  17.858779191970825\n",
            "step :  34600 iters_100_time :  71.05844569206238\n",
            "step :  34700 iters_100_time :  70.99834489822388\n",
            "step :  34800 iters_100_time :  71.11318874359131\n",
            "step :  34900 iters_100_time :  71.00185561180115\n",
            "[219/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 53.25 Time: 315.21s\n",
            "num_batches :  442\n",
            "step :  35000 iters_100_time :  59.18289351463318\n",
            "step :  35100 iters_100_time :  71.16186213493347\n",
            "step :  35200 iters_100_time :  71.2243263721466\n",
            "step :  35300 iters_100_time :  71.07810258865356\n",
            "[220/600][442]\n",
            "                    Loss_D: 0.12 Loss_G: 36.42 Time: 315.62s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  35400 iters_100_time :  29.43305015563965\n",
            "step :  35500 iters_100_time :  71.08632969856262\n",
            "step :  35600 iters_100_time :  71.07983827590942\n",
            "step :  35700 iters_100_time :  71.1434109210968\n",
            "step :  35800 iters_100_time :  71.1515953540802\n",
            "[221/600][442]\n",
            "                    Loss_D: 1.03 Loss_G: 44.03 Time: 315.88s\n",
            "num_batches :  442\n",
            "step :  35900 iters_100_time :  70.67427039146423\n",
            "step :  36000 iters_100_time :  71.1130862236023\n",
            "step :  36100 iters_100_time :  71.10441780090332\n",
            "step :  36200 iters_100_time :  71.08487010002136\n",
            "[222/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 69.98 Time: 315.71s\n",
            "num_batches :  442\n",
            "step :  36300 iters_100_time :  40.72794818878174\n",
            "step :  36400 iters_100_time :  71.23218369483948\n",
            "step :  36500 iters_100_time :  71.18350267410278\n",
            "step :  36600 iters_100_time :  71.16821813583374\n",
            "[223/600][442]\n",
            "                    Loss_D: 0.72 Loss_G: 64.45 Time: 315.92s\n",
            "num_batches :  442\n",
            "step :  36700 iters_100_time :  10.846197843551636\n",
            "step :  36800 iters_100_time :  71.06121182441711\n",
            "step :  36900 iters_100_time :  71.10347270965576\n",
            "step :  37000 iters_100_time :  71.0774884223938\n",
            "step :  37100 iters_100_time :  71.08937811851501\n",
            "[224/600][442]\n",
            "                    Loss_D: 1.03 Loss_G: 40.80 Time: 315.41s\n",
            "num_batches :  442\n",
            "step :  37200 iters_100_time :  52.050416707992554\n",
            "step :  37300 iters_100_time :  71.26008772850037\n",
            "step :  37400 iters_100_time :  71.18075323104858\n",
            "step :  37500 iters_100_time :  71.10742139816284\n",
            "[225/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 44.04 Time: 315.76s\n",
            "num_batches :  442\n",
            "step :  37600 iters_100_time :  22.24716281890869\n",
            "step :  37700 iters_100_time :  71.18650388717651\n",
            "step :  37800 iters_100_time :  71.13999509811401\n",
            "step :  37900 iters_100_time :  71.10513544082642\n",
            "step :  38000 iters_100_time :  71.06364607810974\n",
            "[226/600][442]\n",
            "                    Loss_D: 2.14 Loss_G: 56.19 Time: 315.64s\n",
            "num_batches :  442\n",
            "step :  38100 iters_100_time :  63.274460554122925\n",
            "step :  38200 iters_100_time :  71.0841109752655\n",
            "step :  38300 iters_100_time :  71.00435471534729\n",
            "step :  38400 iters_100_time :  71.06154775619507\n",
            "[227/600][442]\n",
            "                    Loss_D: 0.05 Loss_G: 57.54 Time: 315.18s\n",
            "num_batches :  442\n",
            "step :  38500 iters_100_time :  33.46310353279114\n",
            "step :  38600 iters_100_time :  71.19044995307922\n",
            "step :  38700 iters_100_time :  71.10840630531311\n",
            "step :  38800 iters_100_time :  71.04663920402527\n",
            "[228/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 65.04 Time: 315.45s\n",
            "num_batches :  442\n",
            "step :  38900 iters_100_time :  3.6452012062072754\n",
            "step :  39000 iters_100_time :  71.24450349807739\n",
            "step :  39100 iters_100_time :  71.2187442779541\n",
            "step :  39200 iters_100_time :  71.2090175151825\n",
            "step :  39300 iters_100_time :  71.2492926120758\n",
            "[229/600][442]\n",
            "                    Loss_D: 0.13 Loss_G: 45.82 Time: 315.93s\n",
            "num_batches :  442\n",
            "step :  39400 iters_100_time :  44.95335125923157\n",
            "step :  39500 iters_100_time :  71.13256621360779\n",
            "step :  39600 iters_100_time :  71.16334700584412\n",
            "step :  39700 iters_100_time :  71.16823410987854\n",
            "[230/600][442]\n",
            "                    Loss_D: 0.82 Loss_G: 51.85 Time: 315.71s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  39800 iters_100_time :  15.420433044433594\n",
            "step :  39900 iters_100_time :  71.21002984046936\n",
            "step :  40000 iters_100_time :  71.1919047832489\n",
            "step :  40100 iters_100_time :  71.18680024147034\n",
            "step :  40200 iters_100_time :  71.13470125198364\n",
            "[231/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 56.01 Time: 316.27s\n",
            "num_batches :  442\n",
            "step :  40300 iters_100_time :  56.34164118766785\n",
            "step :  40400 iters_100_time :  71.27616000175476\n",
            "step :  40500 iters_100_time :  71.17753767967224\n",
            "step :  40600 iters_100_time :  71.11821818351746\n",
            "[232/600][442]\n",
            "                    Loss_D: 0.55 Loss_G: 62.85 Time: 315.78s\n",
            "num_batches :  442\n",
            "step :  40700 iters_100_time :  26.40817952156067\n",
            "step :  40800 iters_100_time :  71.10563731193542\n",
            "step :  40900 iters_100_time :  71.09124827384949\n",
            "step :  41000 iters_100_time :  71.18746209144592\n",
            "step :  41100 iters_100_time :  71.12417149543762\n",
            "[233/600][442]\n",
            "                    Loss_D: 0.39 Loss_G: 41.07 Time: 315.55s\n",
            "num_batches :  442\n",
            "step :  41200 iters_100_time :  67.6170768737793\n",
            "step :  41300 iters_100_time :  71.08633351325989\n",
            "step :  41400 iters_100_time :  71.0743305683136\n",
            "step :  41500 iters_100_time :  71.19542098045349\n",
            "[234/600][442]\n",
            "                    Loss_D: 0.20 Loss_G: 43.31 Time: 315.55s\n",
            "num_batches :  442\n",
            "step :  41600 iters_100_time :  37.88825058937073\n",
            "step :  41700 iters_100_time :  71.12520384788513\n",
            "step :  41800 iters_100_time :  71.07326078414917\n",
            "step :  41900 iters_100_time :  71.0125184059143\n",
            "[235/600][442]\n",
            "                    Loss_D: 0.11 Loss_G: 49.39 Time: 315.39s\n",
            "num_batches :  442\n",
            "step :  42000 iters_100_time :  7.985218286514282\n",
            "step :  42100 iters_100_time :  71.06361699104309\n",
            "step :  42200 iters_100_time :  71.06012916564941\n",
            "step :  42300 iters_100_time :  71.06640124320984\n",
            "step :  42400 iters_100_time :  71.02752900123596\n",
            "[236/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 48.63 Time: 315.29s\n",
            "num_batches :  442\n",
            "step :  42500 iters_100_time :  49.24441647529602\n",
            "step :  42600 iters_100_time :  71.09857392311096\n",
            "step :  42700 iters_100_time :  71.15352463722229\n",
            "step :  42800 iters_100_time :  71.03587627410889\n",
            "[237/600][442]\n",
            "                    Loss_D: 0.06 Loss_G: 46.35 Time: 315.50s\n",
            "num_batches :  442\n",
            "step :  42900 iters_100_time :  19.3832426071167\n",
            "step :  43000 iters_100_time :  71.15840578079224\n",
            "step :  43100 iters_100_time :  71.13137650489807\n",
            "step :  43200 iters_100_time :  71.10021448135376\n",
            "step :  43300 iters_100_time :  71.13494062423706\n",
            "[238/600][442]\n",
            "                    Loss_D: 0.30 Loss_G: 44.63 Time: 315.61s\n",
            "num_batches :  442\n",
            "step :  43400 iters_100_time :  60.43085598945618\n",
            "step :  43500 iters_100_time :  71.14286875724792\n",
            "step :  43600 iters_100_time :  71.10041832923889\n",
            "step :  43700 iters_100_time :  71.12394070625305\n",
            "[239/600][442]\n",
            "                    Loss_D: 0.85 Loss_G: 32.34 Time: 315.40s\n",
            "num_batches :  442\n",
            "step :  43800 iters_100_time :  30.65590786933899\n",
            "step :  43900 iters_100_time :  71.12147760391235\n",
            "step :  44000 iters_100_time :  70.98841261863708\n",
            "step :  44100 iters_100_time :  71.12622904777527\n",
            "step :  44200 iters_100_time :  71.15585231781006\n",
            "[240/600][442]\n",
            "                    Loss_D: 0.15 Loss_G: 49.73 Time: 315.44s\n",
            "Save G/Ds models.\n",
            "num_batches :  442\n",
            "step :  44300 iters_100_time :  72.34506940841675\n",
            "step :  44400 iters_100_time :  71.1519603729248\n",
            "step :  44500 iters_100_time :  71.13004541397095\n",
            "step :  44600 iters_100_time :  71.1253113746643\n",
            "[241/600][442]\n",
            "                    Loss_D: 0.35 Loss_G: 49.83 Time: 316.10s\n",
            "num_batches :  442\n",
            "step :  44700 iters_100_time :  42.14791488647461\n",
            "step :  44800 iters_100_time :  71.15943741798401\n",
            "step :  44900 iters_100_time :  71.1746118068695\n",
            "step :  45000 iters_100_time :  71.19080519676208\n",
            "[242/600][442]\n",
            "                    Loss_D: 0.23 Loss_G: 49.83 Time: 315.82s\n",
            "num_batches :  442\n",
            "step :  45100 iters_100_time :  12.211148977279663\n",
            "step :  45200 iters_100_time :  71.10506391525269\n",
            "step :  45300 iters_100_time :  71.09288620948792\n",
            "step :  45400 iters_100_time :  71.04929757118225\n",
            "step :  45500 iters_100_time :  71.11270260810852\n",
            "[243/600][442]\n",
            "                    Loss_D: 0.22 Loss_G: 54.82 Time: 315.44s\n",
            "num_batches :  442\n",
            "step :  45600 iters_100_time :  53.392521142959595\n",
            "step :  45700 iters_100_time :  71.08850717544556\n",
            "step :  45800 iters_100_time :  71.11860585212708\n",
            "step :  45900 iters_100_time :  71.14334797859192\n",
            "[244/600][442]\n",
            "                    Loss_D: 0.77 Loss_G: 59.78 Time: 315.45s\n",
            "num_batches :  442\n",
            "step :  46000 iters_100_time :  23.59966540336609\n",
            "step :  46100 iters_100_time :  71.05986142158508\n",
            "step :  46200 iters_100_time :  71.08318734169006\n",
            "step :  46300 iters_100_time :  71.06667017936707\n",
            "step :  46400 iters_100_time :  70.99656057357788\n",
            "[245/600][442]\n",
            "                    Loss_D: 0.52 Loss_G: 50.97 Time: 315.24s\n",
            "num_batches :  442\n",
            "step :  46500 iters_100_time :  64.84983825683594\n",
            "step :  46600 iters_100_time :  71.00802826881409\n",
            "step :  46700 iters_100_time :  71.13643074035645\n",
            "step :  46800 iters_100_time :  71.09825611114502\n",
            "[246/600][442]\n",
            "                    Loss_D: 0.09 Loss_G: 48.18 Time: 315.44s\n",
            "num_batches :  442\n",
            "step :  46900 iters_100_time :  35.02412223815918\n",
            "step :  47000 iters_100_time :  71.0683159828186\n",
            "step :  47100 iters_100_time :  71.04084610939026\n",
            "step :  47200 iters_100_time :  71.06037998199463\n",
            "[247/600][442]\n",
            "                    Loss_D: 0.10 Loss_G: 50.83 Time: 315.28s\n",
            "num_batches :  442\n",
            "step :  47300 iters_100_time :  5.175745725631714\n",
            "step :  47400 iters_100_time :  70.99250793457031\n",
            "step :  47500 iters_100_time :  71.048184633255\n",
            "step :  47600 iters_100_time :  71.08567094802856\n",
            "step :  47700 iters_100_time :  71.0675139427185\n",
            "[248/600][442]\n",
            "                    Loss_D: 0.35 Loss_G: 78.73 Time: 315.32s\n",
            "num_batches :  442\n",
            "step :  47800 iters_100_time :  46.36119604110718\n",
            "step :  47900 iters_100_time :  71.0755262374878\n",
            "step :  48000 iters_100_time :  71.10836291313171\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7e0n2wtcjT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}